---
title: "Project Checkpoint 5"
author: "Jina Park, Phuc Nguyen"
date: "11/21/2017"
output: html_document
---

### Progress Made

- Examined other research papers with similar topics to derive models for our project.

- Produced 2 models for each of our research questions.

- Cleaned the model data to use with Rjags.

### Group Roles

- We came up with the two research questions together. 

- We worked on formulating the 4 models together by reading past research and altering it with our questions.

- Phuc cleaned the traffic stops data.

- Jina wrote this report with the help of Phuc.

-----------------------------------------------------------

### Research Question 1

- Predicting hotspots of specific crimes and how they changed over time and space.

- Are certain types of crimes more prevalent in certain areas than others? 

- How have these hotspots changed over time? If they have changed over time, how has it changed relative to changes in income, demographics, age, etc?


### Research Question 2

- Examining police traffic stops and subsequent arrests to determine whether certain ethnic minorities are stopped/arrested more than others.

- Are certain ethnic groups more likely to be arrested/stopped in certain areas than others? For instance, are blacks/hispanics more likely to be stopped/arrested in predominantly white neighborhoods?

- We would like to examine the relationship between traffic stops/arrests and the actual crime rates of different ethnic groups. For instance, are blacks/hispanics getting stopped/arrested at a disproportionately greater rate than they are committing crimes? 


#### Load Libraries
```{r}
library(tidyr)
library(rjags)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(MacBayes)
library(choroplethrZip)
library(rgdal)
```

#### Clean data
```{r}
#Load data
Crime = read.csv('Crime_sample_2010_to_2017.csv')

Crime = Crime %>%
  mutate(Date = as.POSIXct(strptime(Date, "%Y-%m-%d %H:%M:%S"))) %>%
  filter(!is.na(Latitude))
```


#### Project observations to ZIP codes boundaries
```{r}
#load shapefile
zip_shp <- readOGR(dsn="Boundaries - ZIP Codes", layer="geo_export_e1262361-5c82-45ee-8427-ef228e06dc4a")
temp <- zip_shp
zip_df <- fortify(temp, region = "zip")

#needs to reassign CRS for shapefile
new_CRS <- CRS("+init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
zip_shp <- sp::spTransform(zip_shp, new_CRS)

#summarize crime count per year
years <- unique(Crime$Year)
Hotspot_Crime <- data.frame()

for(i in 1:length(years)){
  year <- years[i]
  Current_Year <- Crime %>% filter(Year == year)
  
  locations <- with(Current_Year, as.data.frame(cbind(Longitude, Latitude)))
  coordinates(locations) <- ~Longitude+Latitude
  proj4string(locations) <- CRS("+init=epsg:4326")
      
  #prepping the data: project points to polygons
  proj4string(zip_shp) <- new_CRS
  proj4string(locations) <- new_CRS
  by_zip <- over(locations, zip_shp)
  
  by_zip <- by_zip %>%
    group_by(zip) %>%
    dplyr::summarise(total=n()) %>%
    filter(!is.na(zip)) %>%
    mutate(id = as.character(zip))
  
  total_map <- left_join(zip_df, by_zip)
  total_map <- total_map %>% mutate(Year = year)
  
  Hotspot_Crime <- rbind(Hotspot_Crime, total_map)
}
```

#### Add demographic information to Model Data
```{r}
data("df_zip_demographics")
Demographics <- df_zip_demographics %>% mutate(zip = region)
Hotspot_Crime <- inner_join(Hotspot_Crime, Demographics, by="zip") 
Model_Data <- Hotspot_Crime %>%
  select(-c(lat, long, order, piece, group, hole)) %>% distinct
```

#### Get populations by zipcode and year
```{r}
Year <- Model_Data %>%
  select(Year, zip, total) %>%
  spread( key=Year, value=total)
rownames(Year) <- Year$zip 
Year <- Year %>% select(-zip)
Year[is.na(Year)] <- 0

Population <- Model_Data %>%
  select(total_population, zip, Year) %>%
  spread(key=Year, value=total_population) 
rownames(Population) <- Population$zip
Population <- Population %>% select(-zip)
Population[is.na(Population)] <- 0

time <- sort(unique(Model_Data$Year))

percent_nonwhite <- 100 - Model_Data$percent_white
```

---------------------------------------------------------------

#### Simulation

# Research Question 1
## Model 1

### Notation
- i: zipcodes in Chicago (58 total in our data)

- j: years (from 2010 to 2017)

- y[i, j]: observed count of violent crimes in Chicago by year and zipcode

- p[i, j]: probability of being a victim in location i and time j

- n[i, j]: the population in zipcode i in time j.

- alpha: the mean crime rate

- u[i]: the unstructured spatial random effect for each zipcode in Chicago.

- s[i]: the structured spatial random effect for each zipcode in Chicago.

- beta: time trend

- time[j]: the time in years

- delta[i]: the spatial temporal interaction term

### Specify the Model
We are modeling the count of crime incidents by year and zipcodes using a binomial distribution, in which the parameters are the probability of being a victim and the total population in location i and year j.

We modeled the probability of being a victim using a logit function of the grand crime rate of Chicago and the inclusion of several random effects. It is also a function of time and its interaction with location.

```{r}
#Specify the model
crime_model_1 <- "model{
    #Data
    for(i in 1:58) {
      for(j in 1:8){
        y[i,j] ~ dbin(p[i,j], n[i,j])
        logit(p[i,j]) = alpha + u[i] + s[i] + beta*time[j] + delta[i]*time[j]
      }
    }
    
    #Priors
    alpha ~ dunif(-1000, 1000)
    beta ~ dnorm(0, 1/1000)
    for(i in 1:58){
      u[i] ~ dnorm(0, prec.u)
      s[i] ~ dnorm(0, prec.s)
      delta[i] ~ dnorm(0, prec.delta)
    }

    #Hyperpriors
    prec.u ~ dgamma(0.5, 0.0005)
    prec.s ~ dgamma(0.5, 0.0005)
    prec.delta ~ dgamma(0.5, 0.0005)
    
}"

#set up an algorithm to simulate the posterior by 
#combining the model (nba_model) and data (y)
#set the random number seed
crime_jags_1 <- jags.model(textConnection(crime_model_1), data=list(y=Year, n=Population, time=time),
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))


 #simulate a sample from the posterior 
#note that we specify both mu and tau variables
crime_sim_1 <- coda.samples(crime_jags_1, variable.names=c("p", "u", "s", "delta", "alpha", "beta"), n.iter=60000)


#store the samples in a data frame:    
crime_data_1 <- data.frame(step=1:60000, crime_sim_1[[1]])
```

### Parameter Interpretation

There is a 73.4% probability that the crime rate in Chicago is positive. The 95% confidence interval of alpha is (-1.28, 1.517).

```{r}
ggplot(crime_data_1, aes(x=alpha)) + geom_histogram(aes(y=..density..), colour="white")
sum(crime_data_1$alpha > 0)/40000
quantile(crime_data_1$alpha, c(0.025, 0.975))
```

It appears that beta, the time trend, is slightly negative. This suggests that the amount of crime in Chicago might be decreasing over time.

```{r}
ggplot(crime_data_1, aes(x=beta)) + geom_histogram(aes(y=..density..), colour="white")
```

-----------------------------------------------------------------

## Model 2 - Overall time trend ($\beta$) is removed from the model

### Notation
- i: zipcodes in Chicago (58 total in our data)

- j: years (from 2010 to 2017)

- y[i, j]: observed count of violent crimes in Chicago by year and zipcode

- p[i, j]: probability of being a victim in location i and time j

- n[i, j]: the population in zipcode i in time j.

- alpha: the mean crime rate

- u[i]: the unstructured spatial random effect for each zipcode in Chicago.

- s[i]: the structured spatial random effect for each zipcode in Chicago.

- time[j]: the time in years

- delta[i]: the spatial temporal interaction term

### Specify the Model
This model resembles Model 1 but we are no longer taking into account the time trend.

```{r}
#Specify the model
crime_model_2 <- "model{
    #Data
    for(i in 1:58) {
      for(j in 1:8){
        y[i,j] ~ dbin(p[i,j], n[i,j])
        logit(p[i,j]) = alpha + u[i] + s[i]+ delta[i]*time[j]
      }
    }
    
    #Priors
    alpha ~ dunif(-1000, 1000)
    beta ~ dnorm(0, 1/1000)
    for(i in 1:58){
      u[i] ~ dnorm(0, prec.u)
      s[i] ~ dnorm(0, prec.s)
      delta[i] ~ dnorm(0, prec.delta)
    }

    #Hyperpriors
    prec.u ~ dgamma(0.5, 0.0005)
    prec.s ~ dgamma(0.5, 0.0005)
    prec.delta ~ dgamma(0.5, 0.0005)
    
}"

#set up an algorithm to simulate the posterior by 
#combining the model (nba_model) and data (y)
#set the random number seed
crime_jags_2 <- jags.model(textConnection(crime_model_2), data=list(y=Year, n=Population, time=time),
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))


#simulate a sample from the posterior 
#note that we specify both mu and tau variables
crime_sim_2 <- coda.samples(crime_jags_2, variable.names=c("p", "u", "s", "delta", "alpha"), n.iter=40000)


#store the samples in a data frame:    
crime_data_2 <- data.frame(step=1:40000, crime_sim_2[[1]])
```

------------------------------------------------------------

# Model 3 -- Use demographics information 

### Notation
- i: zipcodes in Chicago (58 total in our data)

- j: years (from 2010 to 2017)

- y[i, j]: observed count of violent crimes in Chicago by year and zipcode

- p[i, j]: probability of being a victim in location i and time j

- n[i, j]: the population in zipcode i in time j.

- alpha: the mean crime rate

- u[i]: the unstructured spatial random effect for each zipcode in Chicago.

- s[i]: the structured spatial random effect for each zipcode in Chicago.

- time[j]: the time in years

- delta[i]: the spatial temporal interaction term

- sigma[i]: the income trend

- income[i]: income for each zipcode in Chicago

### Specify the Model
This model resembles Model 2 but now our prediction of the crime rate accounts for the different income levels in various Chicago zipcodes.

```{r}
#Specify the model
crime_model_3 <- "model{
    #Data
    for(i in 1:58) {
      for(j in 1:8){
        y[i,j] ~ dbin(p[i,j], n[i,j])
        logit(p[i,j]) = alpha + u[i] + s[i]+ delta[i]*time[j] + sigma[i]*income[i]
      }
    }
    
    #Priors
    alpha ~ dunif(-1000, 1000)
    beta ~ dnorm(0, 1/1000)
    for(i in 1:58){
      u[i] ~ dnorm(0, prec.u)
      s[i] ~ dnorm(0, prec.s)
      delta[i] ~ dnorm(0, prec.delta)
      sigma[i] ~ dnorm(0, prec.sigma)
    }

    #Hyperpriors
    prec.u ~ dgamma(0.5, 0.0005)
    prec.s ~ dgamma(0.5, 0.0005)
    prec.delta ~ dgamma(0.5, 0.0005)
    prec.sigma ~ dgamma(0.5, 0.0005)
    
}"

#set up an algorithm to simulate the posterior by 
#combining the model (nba_model) and data (y)
#set the random number seed
crime_jags_3 <- jags.model(textConnection(crime_model_3), data=list(y=Year, n=Population, time=time, income=Model_Data$per_capita_income),
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))


#simulate a sample from the posterior 
#note that we specify both mu and tau variables
crime_sim_3 <- coda.samples(crime_jags_3, variable.names=c("p", "u", "s", "delta", "alpha", "sigma"), n.iter=40000)


#store the samples in a data frame:    
crime_data_3 <- data.frame(step=1:40000, crime_sim_3[[1]])
```

### Running mean plot of alpha

```{r}
library(MacBayes)
running_mean_plot(crime_data_3$alpha)
```

# Model 4 -- Use demographics information with race

### Notation
- i: zipcodes in Chicago (58 total in our data)

- j: years (from 2010 to 2017)

- y[i, j]: observed count of violent crimes in Chicago by year and zipcode

- p[i, j]: probability of being a victim in location i and time j

- n[i, j]: the population in zipcode i in time j.

- alpha: the mean crime rate

- u[i]: the unstructured spatial random effect for each zipcode in Chicago.

- s[i]: the structured spatial random effect for each zipcode in Chicago.

- time[j]: the time in years

- delta[i]: the spatial temporal interaction term

- sigma[i]: the income trend

- income[i]: income for each zipcode in Chicago

- e[i]: the weight in the relationship between crime rate and percentage of nonewhite people in Chicago

- percent_nonwhite[i]: the percentage of nonwhite people in zipcode i.

### Specify the Model
This model resembles Model 3 but now our prediction of the crime rate accounts for both income levels and the percentage of nonwhites in the area.

```{r}
#Specify the model
crime_model_4 <- "model{
    #Data
    for(i in 1:58) {
      for(j in 1:8){
        y[i,j] ~ dbin(p[i,j], n[i,j])
        logit(p[i,j]) = alpha + u[i] + s[i]+ delta[i]*time[j] + sigma[i]*income[i] + e[i]*percent_nonwhite[i]
      }
    }
    
    #Priors
    alpha ~ dunif(-1000, 1000)
    beta ~ dnorm(0, 1/1000)
    for(i in 1:58){
      u[i] ~ dnorm(0, prec.u)
      s[i] ~ dnorm(0, prec.s)
      delta[i] ~ dnorm(0, prec.delta)
      sigma[i] ~ dnorm(0, prec.sigma)
      e[i] ~ dnorm(0, 0.01)
    }

    #Hyperpriors
    prec.u ~ dgamma(0.5, 0.0005)
    prec.s ~ dgamma(0.5, 0.0005)
    prec.delta ~ dgamma(0.5, 0.0005)
    prec.sigma ~ dgamma(0.5, 0.0005)
    
}"

#set up an algorithm to simulate the posterior by 
#combining the model (nba_model) and data (y)
#set the random number seed
crime_jags_4 <- jags.model(textConnection(crime_model_4), data=list(y=Year, n=Population, time=time, income=Model_Data$per_capita_income, percent_nonwhite=percent_nonwhite),
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))


#simulate a sample from the posterior 
#note that we specify both mu and tau variables
crime_sim_4 <- coda.samples(crime_jags_4, variable.names=c("p", "u", "s", "delta", "alpha", "sigma", "e"), n.iter=40000)


#store the samples in a data frame:    
crime_data_4 <- data.frame(step=1:40000, crime_sim_4[[1]])
```

------------------------------------------------------------------------


# Police model

### Cleaning the data
```{r}
#number of zipcodes: 62
#number races 7
Police <- read.csv("Police_stops_2016_2017_sample.csv")

Police.r <- Police %>%
  filter(!(RACE_CODE_CD=="I" | RACE_CODE_CD=="P" | RACE_CODE_CD=="WHI") ) %>%
  mutate(RACE_CODE_CD = as.character(RACE_CODE_CD)) %>%
  mutate(RACE_CODE_CD=replace(RACE_CODE_CD, RACE_CODE_CD=="WWH", "HISPANIC"))

vars = c("percent_white","percent_black","percent_asian","percent_hispanic")
Population.race <- Model_Data %>%
  mutate_at(vars, function(x){trunc(Model_Data$total_population*x/100)}) %>%
  select(zip, percent_asian,percent_black,percent_hispanic, percent_white) %>%
  unique() %>%
  remove_rownames %>%
  column_to_rownames(var='zip') 

valid_zips <- unique(rownames(Population.race))

Arrests <- Police.r %>% 
  filter(ZIP_CD %in% valid_zips) %>%
  group_by(ZIP_CD, RACE_CODE_CD) %>%
  dplyr::summarise(total.arrest = sum(ENFORCEMENT_ACTION_TAKEN_I)) %>%
  spread(key=ZIP_CD, value=total.arrest) %>%
  as.data.frame() %>%
  remove_rownames %>%
  column_to_rownames(var='RACE_CODE_CD')
Arrests[is.na(Arrests)] <- 0

Stops <- Police.r %>%
  filter(ZIP_CD %in% valid_zips) %>%
  group_by(ZIP_CD, RACE_CODE_CD) %>%
  dplyr::summarise(total.stop = n()) %>%
  spread(key=ZIP_CD, value=total.stop) %>%
  as.data.frame() %>%
  remove_rownames %>%
  column_to_rownames(var='RACE_CODE_CD')
Stops[is.na(Stops)] <- 0
```


-------------------------------------------------------------------------

## Research Question 2 - Model 1

### Notation
- Data is only from January 2016 - February 2017 (13/12)

- i: ethnic group

- j: zipcode locations in Chicago

- y[i, j]: observed number of arrests of ethnic group i in area j

- n[i, j]: the number of traffic stops in area j for ethnic group i

- mu: grand mean of arrests

- alpha[i]: the random effect for each ethnic group i

- beta[j]: the random effect for each zipcode location j

- epsilon[i, j]: the random error for each ethnic group i and location j

### Specify the Model

We are modeling the arrest rate by ethnic group and location using a poisson distribution, in which the number of traffic stops acts as a baseline for the number of arrests. 

```
#Specify the model
police_model_1 <- "model{
    #Data
    for(i in 1:4) {
      for(j in 1:58){
        y[i,j] ~ dpois((13/12)*n[i,j]* exp(mu + alpha[i] + beta[j] + epsilon[i,j])
      }
    }
    
    #Priors
    mu ~ dunif(-500, 500)

    for (j in 1: 58){
      beta[j] ~ dnorm(0, 1/sigma_beta^2)
    }

    for (i in 1:4){
      alpha[i] ~ dunif(-50, 50)
    }

    for (i in 1:4){
      for (j in 1:62){
        epsilon[i,j] ~ dnorm(0, 1/sigma_epsilon^2)
      }
    }

    #Hyperpriors
    sigma_beta ~ dunif(0.00001, 0.01)
    sigma_epsilon ~ dunif(0.00001, 0.01)
    
}"

#set up an algorithm to simulate the posterior by 
#combining the model and data (y)
#set the random number seed
police_jags_1 <- jags.model(textConnection(police_model_1), data=list(y=Stops, n=Arrests),
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))


#simulate a sample from the posterior 
#note that we specify both mu and tau variables
police_sim_1 <- coda.samples(police_jags_1, variable.names=c("mu", "alpha", "sigma_beta", "sigma_epsilon", "beta", "epsilon", "theta"), n.iter=10000)


#store the samples in a data frame:    
police_data_1 <- data.frame(step=1:10000, police_sim_1[[1]])
```


##Model 2
=======
------------------------------------------------------------

## Research Question 2: Model 2

### Notation
- Data is only from January 2016 - February 2017 (13/12)

- i: ethnic group

- j: zipcode locations in Chicago

- y[i, j]: observed number of arrests of ethnic group i in area j

- n[i, j]: the number of traffic stops in area j for ethnic group i

- theta[i, j]: the true crime rate for each ethnic group i in location j

- alpha: represents some relationship between crime rate and the number of arrests.

- N[j, i]: the population of ethnic group i and area j

- beta: error term

### Specify the Model

This model resembles Model 1 but takes into account the population of ethnic groups in each zipcode.

```
#Specify the model
police_model_2 <- "model{
    #Data
    for(i in 1:4) {
      for(j in 1:58){
        y[i,j] ~ dpois((13/12)*theta[i,j]*exp(alpha))
        n[i,j] ~ dpois(theta[i,j])
        log(theta[i,j]) = log(N[j,i]) + beta[i, j]
      }
    }
    
    #Priors
    alpha ~ dunif(-100, 100)

    for (i in 1:4) {
       for (j in 1:58){
           beta[i,j] ~ dnorm(0, 1/sigma_epsilon^2)
         }
    }

}"

#set up an algorithm to simulate the posterior by 
#combining the model and data (y)
#set the random number seed
police_jags_2 <- jags.model(textConnection(police_model_2), data=list(n=Stops, y=Arrests, N=Population.race),
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))


#simulate a sample from the posterior 
#note that we specify both mu and tau variables
police_sim_2 <- coda.samples(police_jags_2, variable.names=c("alpha",  "beta",  "theta"), n.iter=10000)


#store the samples in a data frame:    
police_data_2 <- data.frame(step=1:10000, police_sim_2[[1]])
```


# Model 3

- i: ethnic group

- j: zipcode locations in Chicago

- y[i, j]: observed number of arrests of ethnic group i in area j

- n[i, j]: the number of traffic stops in area j for ethnic group i

- theta[i, j]: the true crime rate for each ethnic group i in location j

- beta0: base rate of arrests

- beta1: base strength of the relationship between number of stops and number of arrests

- beta2[i]: pump in strength of relationship between number of stops and number of arrests for race i

### Specify the Model

This model models the number of arrests based on number of stops with a Poisson distribution and a different rate for each ethnic group. 


```{r, cache=TRUE}
police_model_3 <- "model{
  for (i in 1:4) {
    for(j in 1:58){
      y[i,j] ~ dpois(theta[i,j])
      log(theta[i,j]) <- beta0 + (beta1 + beta2[i])*n[i,j]
    }
  }

  beta0 ~ dnorm(0,1.0E-06)
  beta1 ~ dnorm(0,1.0E-06)
  for (i in 1:4){
    beta2[i] ~ dnorm(0,1.0E-06)
  }
}"


police_jags_3 <- jags.model(textConnection(police_model_3), data=list(y=Arrests, n=Stops),
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))


#simulate a sample from the posterior 
#note that we specify both mu and tau variables
police_sim_3 <- coda.samples(police_jags_3, variable.names=c( "beta0", "beta1", "beta2"), n.iter=20000)


#store the samples in a data frame:    
police_data_3 <- data.frame(step=1:20000, police_sim_3[[1]])
```

###Parameters interpretation

```{r}
plot(police_sim_3)
```

```{r}
quantile(police_data_3$beta2.1, c(0.025, 0.975))
quantile(police_data_3$beta2.2, c(0.025, 0.975))
quantile(police_data_3$beta2.3, c(0.025, 0.975))
quantile(police_data_3$beta2.4, c(0.025, 0.975))
```

There is a 95% chance that the random effect of race on the number of arrests given the number of stop is within the following intervals: (-0.8, -0.5) for Asian, (-0.02, -0.01) for Black, (-0.01, -0.00) for Hispanic, and (-0.03, -0.02) for White. It seems that for Asian and White, arrest rates per stop are lower. 


# Model 4

- i: ethnic group

- j: zipcode locations in Chicago

- y[i, j]: observed number of arrests of ethnic group i in area j

- n[i, j]: the number of traffic stops in area j for ethnic group i

- theta[i, j]: the true crime rate for each ethnic group i in location j

- alpha: represents some relationship between crime rate and the number of arrests.

- N[j, i]: the population of ethnic group i and area j

- beta: error term



```{r, cache=TRUE}
police_model_4 <- "model{
  for (i in 1:4) {
    for(j in 1:58){
      y[i,j] ~ dpois(theta[i,j])
      log(theta[i,j]) <- beta0 + beta2[i] + beta3[j] + beta1*n[i,j]
    }
  }

  beta0 ~ dnorm(0,1.0E-06)
  beta1 ~ dnorm(0,1.0E-06)
  for (i in 1:4){
    beta2[i] ~ dnorm(0,1.0E-06)
  }
  for (j in 1: 58){
    beta3[j] ~ dnorm(0,1.0E-06)
  }

}"


police_jags_4 <- jags.model(textConnection(police_model_4), data=list(y=Arrests, n=Stops),
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))


#simulate a sample from the posterior 
#note that we specify both mu and tau variables
police_sim_4 <- coda.samples(police_jags_4, variable.names=c( "beta0", "beta1", "beta2", "beta3"), n.iter=20000)


#store the samples in a data frame:    
police_data_4 <- data.frame(step=1:20000, police_sim_4[[1]])
```


```{r}
running_mean_plot(police_data_4$beta0)
running_mean_plot(police_data_4$beta1)
running_mean_plot(police_data_4$beta2.2)
```

