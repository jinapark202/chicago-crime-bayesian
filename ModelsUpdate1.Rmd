---
title: "Models Update"
author: "Jina Park, Phuc Nguyen"
date: "12/5/2017"
output: html_document
---

### Progress Made


### Group Roles


-----------------------------------------------------------

### Research Question 1

- Predicting hotspots of specific crimes and how they changed over time and space.

- Are certain types of crimes more prevalent in certain areas than others? 

- How have these hotspots changed over time? If they have changed over time, how has it changed relative to changes in income, demographics, age, etc?


### Research Question 2

- Examining police traffic stops and subsequent arrests to determine whether certain ethnic minorities are stopped/arrested more than others.

- Are certain ethnic groups more likely to be arrested/stopped in certain areas than others? For instance, are blacks/hispanics more likely to be stopped/arrested in predominantly white neighborhoods?

- We would like to examine the relationship between traffic stops/arrests and the actual crime rates of different ethnic groups. For instance, are blacks/hispanics getting stopped/arrested at a disproportionately greater rate than they are committing crimes? 

#### Load Libraries
```{r message=FALSE, warning=FALSE}
library(tidyr)
library(rjags)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(MacBayes)
library(choroplethrZip)
library(rgdal)
```

#### Map cleanup
```{r}
cleanup <- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = 'white', colour = 'white'),
        axis.line = element_line(colour = "white"),
        axis.ticks=element_blank(), axis.text.x=element_blank(),
        axis.text.y=element_blank())
```

#### Clean data
```{r message=FALSE, warning=FALSE}
#Load data
Crime = read.csv('Crime_sample_2010_to_2017.csv')

Crime = Crime %>%
  mutate(Date = as.POSIXct(strptime(Date, "%Y-%m-%d %H:%M:%S"))) %>%
  filter(!is.na(Latitude))
```

#### Project observations to ZIP codes boundaries
```{r message=FALSE, warning=FALSE}
#load shapefile
zip_shp <- readOGR(dsn="Boundaries - ZIP Codes", layer="geo_export_e1262361-5c82-45ee-8427-ef228e06dc4a")
temp <- zip_shp
zip_df <- fortify(temp, region = "zip")

#needs to reassign CRS for shapefile
new_CRS <- CRS("+init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
zip_shp <- sp::spTransform(zip_shp, new_CRS)

#summarize crime count per year
years <- unique(Crime$Year)
Hotspot_Crime <- data.frame()

for(i in 1:length(years)){
  year <- years[i]
  Current_Year <- Crime %>% filter(Year == year)
  
  locations <- with(Current_Year, as.data.frame(cbind(Longitude, Latitude)))
  coordinates(locations) <- ~Longitude+Latitude
  proj4string(locations) <- CRS("+init=epsg:4326")
      
  #prepping the data: project points to polygons
  proj4string(zip_shp) <- new_CRS
  proj4string(locations) <- new_CRS
  by_zip <- over(locations, zip_shp)
  
  by_zip <- by_zip %>%
    group_by(zip) %>%
    dplyr::summarise(total=n()) %>%
    filter(!is.na(zip)) %>%
    mutate(id = as.character(zip))
  
  total_map <- left_join(zip_df, by_zip)
  total_map <- total_map %>% mutate(Year = year)
  
  Hotspot_Crime <- rbind(Hotspot_Crime, total_map)
}
```

#### Add demographic information to Model Data
```{r message=FALSE, warning=FALSE}
data("df_zip_demographics")
Demographics <- df_zip_demographics %>% mutate(zip = region)
Hotspot_Crime <- inner_join(Hotspot_Crime, Demographics, by="zip") 
Model_Data <- Hotspot_Crime %>%
  select(-c(lat, long, order, piece, group, hole)) %>% distinct
```

#### Add and transform some variables

```{r}
#variables to use: zip, year, crime count (total), population, income, percent nonwhite

Model_Data <- transform(Model_Data, id=match(zip, unique(zip)))
Model_Data$racegr <- ifelse(Model_Data$percent_white >66, 1, ifelse(Model_Data$percent_white <=33, 3, 2)) 
Model_Data$area_white <- recode(Model_Data$racegr, `1`=1, .default = 0)
Model_Data$area_mid <- recode(Model_Data$racegr, `2`=1, .default = 0)
Model_Data$area_poc <- recode(Model_Data$racegr, `3`=1, .default = 0)
```


---------------------------------------------------------------

#### Simulation
# Research Question 1

**Plot of $log(y_{ij}/n_{i})$ vs year**
```{r}

Crime_count_log <- Model_Data %>%
  mutate(log_rate = log(total/total_population)) %>%
  select(zip, Year, log_rate)
head(Crime_count_log)

ggplot(Crime_count_log, aes(x=Year, y=log_rate, colour=zip)) + geom_point() + geom_line() 
```

**Plot of $$log(y_{ij}/n_{i})$$ vs per capita income**
```{r}
Model_Data_1 <- Model_Data %>%
  filter(Year == 2010) %>%
  mutate(percent_nonwhite = 100 - percent_white) %>%
  select(zip, per_capita_income, percent_nonwhite) %>%
  right_join(Crime_count_log, by="zip") 

head(Model_Data_1)

ggplot(Model_Data_1, aes(x=log(per_capita_income), y=log_rate, colour=percent_nonwhite)) + geom_point() + labs(x="Log of Per Capita Income", y="Log of Crime Rate", title="Relationship between Per Capita Income and Log of Crime Rate")
```

**Plot of $log(y_{ij}/n_{i})$ vs nonwhite percentage**
```{r}
ggplot(Model_Data_1, aes(x=log(percent_nonwhite), y=crime_count_log)) + geom_point() + labs(x="Log of Nonwhite Percentage", y="Log of Crime Rate", title="Relationship between Nonwhite Percentage and Log of Crime Rate")
```


## Model 0
#### Data
$$y_{ij} \sim Bin(p_{ij}, n_{i})$$
$$logit(p_{ij}) = \alpha + \beta * time_{j}$$

#### Priors
$$\alpha \sim N(0, 1000^2)$$
$$\beta \sim N(0, 1000^2)$$

- i: zipcodes in Chicago (58 total in our data)

- j: years (from 2010 to 2017)

- y[i, j]: observed count of violent crimes in Chicago by year and zipcode

- p[i, j]: probability of being a victim in location i and time j

- n[i]: the population in zipcode i

- $\beta$: time trend

- time[j]: the time in years

```{r}
#Data
Crime_count <- Model_Data %>%
  group_by(Year) %>%
  dplyr::summarise(total.stop = sum(total))
head(Crime_count)
```

```{r, cache=TRUE}
#Specify the model
crime_model_0 <- "model{
    #Data
    for(j in 1:6){
      y[j] ~ dbin(p[j], n)
      logit(p[j]) = beta*time[j]
    }
    
    #Priors
    beta ~ dnorm(0, 1/100^2)

}"

#set up an algorithm to simulate the posterior by 
#combining the model (nba_model) and data (y)
#set the random number seed
crime_jags_0 <- jags.model(textConnection(crime_model_0), data=list(y=Crime_count$total.stop, n=sum(Population.vector), time=Crime_count$Year),inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))
#crime_jags_0 <- jags.model(textConnection(crime_model_0), data=list(y=Crime_count$total.stop, n=sum(Population.vector), #time=Crime_count$Year),inits=list(alpha=-8, beta=-0.04))


#simulate a sample from the posterior 
crime_sim_0 <- coda.samples(crime_jags_0, variable.names=c("beta"), n.iter=50000)


#store the samples in a data frame:    
crime_data_0 <- data.frame(crime_sim_0[[1]])
```

### Running Mean Plot

The running mean plot shows that beta is stabilized at $n=40000$.

```{r}
running_mean_plot(crime_data_0$beta)
```

### Parameter Inferences
```{r}
ggplot(crime_data_0, aes(x=beta)) + geom_histogram(aes(y=..density..), colour="white") + labs(title="Posterior Distribution of the Effect of Time", x="Time Effect", y="Density")
```

The posterior mean is -0.003811, and 95% percent chance that the true time trend over log crime rate is between -0.003822 and -0.003811. So the predicted crime incidents for 2016 is $Population * exp(-0.003811 * 2016) = 1246.776$ compared to the actual number of 1082, which is a 15% error rate in prediction.

### Confidence Intervals and Posterior Means of Crime Model 0 parameters
```{r}
crime_model_0_CI <- matrix(nrow=9, ncol=2)
for (i in 1:9) {
      crime_model_0_CI[i,] <- quantile(crime_data_0[[i]], c(0.025, 0.975))
}

crime_model_0_mean <- matrix(nrow=9, ncol=1)
for (i in 1:9) {
      crime_model_0_mean[i, ] <- mean(crime_data_0[[i]])
}

crime_model_0_table <- cbind(crime_model_0_CI, crime_model_0_mean)
rownames(crime_model_0_table) <- names(crime_data_0)
colnames(crime_model_0_table) <- c("2.5%", "97.5%", "Mean")
as.table(crime_model_0_table)
```

## Model 1
### Notation
- i: zipcodes in Chicago (58 total in our data)

- j: years (from 2010 to 2017)

- y[i, j]: observed count of violent crimes in Chicago by year and zipcode

- p[i, j]: probability of being a victim in location i and time j

- n[i, j]: the population in zipcode i in time j.

- time[j]: the time in years

- $\delta$[i]: the spatial temporal interaction term

### Specify the Model
We are modeling the count of crime incidents by year and zipcodes using a binomial distribution, in which the parameters are the probability of being a victim and the total population in location i and year j.

We modeled the probability of being a victim using a logit function of the grand crime rate of Chicago and time and its interaction with location.

#### Data
$$y_{ij} \sim Bin(p_{ij}, n_{i})$$
$$logit(p_{ij}) = \delta_{i} * time_{j}$$

#### Priors
$$\delta_{i} \sim N(0, prec.delta)$$

#### Hyperpriors
$$prec.delta \sim Gamma(0.5, 0.0005)$$

```{r}
#Data
data = list(y=Model_Data$total, n=Model_Data$total_population, time=Model_Data$Year, zipid=Model_Data$id, ns=length(Model_Data$total), nzip=length(unique(Model_Data$id)))
```

```{r, cache=TRUE}
#Specify the model
crime_model_1 <- "model{
    #Data
    for(i in 1:ns) {
      y[i] ~ dbin(p[i], n[i])
      logit(p[i]) = delta[zipid[i]]*time[i]
    }
    
    #Priors
    for(j in 1:nzip){
      delta[j] ~ dnorm(0, prec.delta)
    }

    #Hyperpriors
    prec.delta ~ dgamma(0.5, 0.0005)
    
}"

#set up an algorithm to simulate the posterior by 
#combining the model (nba_model) and data (y)
#set the random number seed
init.rng1<-list(".RNG.seed" = 1998, ".RNG.name" = "base::Mersenne-Twister")
crime_jags_1 <- jags.model(textConnection(crime_model_1), data=data,
                    inits=init.rng1)


 #simulate a sample from the posterior 
#note that we specify both mu and tau variables
update(crime_jags_1, 10000)
crime_sim_1 <- coda.samples(crime_jags_1, variable.names=c("delta"), n.iter=10000)


#store the samples in a data frame:    
crime_data_1 <- data.frame( crime_sim_1[[1]])
```

**Check for convergence**
```{r}
running_mean_plot(crime_data_1$delta.1.)
```

### Parameter Interpretation

Example of posterier distribution for delta of first zipcode:

```{r message=FALSE, warning=FALSE}
ggplot(crime_data_1, aes(x=delta.1.)) + geom_histogram(aes(y=..density..), colour="white") + labs(title="Posterior Distribution of the Crime Differential Growth in 2010", x="Crime Differential Growth", y="Density")
```


### Confidence Intervals and Posterior Mean of Crime Model 0 parameters
```{r}
crime_model_1_CI <- matrix(nrow=length(names(crime_data_1)), ncol=2)
for (i in 1:length(names(crime_data_1))) {
      crime_model_1_CI[i, ] <- quantile(crime_data_1[[i]], c(0.025, 0.975))
}

crime_model_1_mean <- matrix(nrow=length(names(crime_data_1)), ncol=1)
for (i in 1:length(names(crime_data_1))) {
      crime_model_1_mean[i, ] <- mean(crime_data_1[[i]])
}

crime_model_1_table <- cbind(crime_model_1_CI, crime_model_1_mean)
rownames(crime_model_1_table) <- names(crime_data_1)
colnames(crime_model_1_table) <- c("2.5%", "97.5%", "Mean")
as.table(crime_model_1_table)
```

```{r}
zip <- readOGR(dsn="Boundaries - ZIP Codes", layer="geo_export_e1262361-5c82-45ee-8427-ef228e06dc4a")
zip_df <- fortify(zip, region = "zip")
zip_df <- left_join(zip_df, data.frame(id=unique(Model_Data$zip), delta=crime_model_1_mean), by='id')
head(zip_df)

model_2_map <- ggplot() 
model_2_map <- model_2_map +  geom_polygon(data = zip_df, aes(x=long, y=lat, group=group, fill=delta), color = "black", size=0.2) 
model_2_map <- model_2_map + coord_map() 
model_2_map <- model_2_map + labs(title=paste("Crime Differential Growth by Zipcode"), fill="total")
print(model_2_map)
```

------------------------------------------------------------------------------

# Model 2 -- Use demographics information 

### Notation
- i: zipcodes in Chicago (58 total in our data)

- j: years (from 2010 to 2017)

- y[i, j]: observed count of violent crimes in Chicago by year and zipcode

- p[i, j]: probability of being a victim in location i and time j

- n[i, j]: the population in zipcode i in time j.

- $\alpha$: the mean crime rate

- u[i]: the unstructured spatial random effect for each zipcode in Chicago.

- time[j]: the time in years

- $\delta$[i]: the spatial temporal interaction term

- $\sigma$[i]: the income trend

- income[i]: income for each zipcode in Chicago

### Specify the Model
This model resembles Model 2 but now our prediction of the crime rate accounts for the different income levels in various Chicago zipcodes.

#### Data
$$y_{ij} \sim Bin(p_{ij}, n_{i})$$
$$logit(p_{ij}) = \alpha + u_{i} + \delta_{i} * time_{j} + \sigma_{i} * income_{i}$$

#### Priors
$$\alpha \sim N(0, 1000^2)$$
$$\beta \sim N(0, 1000^2)$$
$$u_{i} \sim N(0, prec.u)$$
$$\delta_{i} \sim N(0, prec.delta)$$
$$\sigma_{i} \sim N(0, prec.sigma)$$

#### Hyperprior
$$prec.u \sim Gamma(0.5, 0.0005)$$
$$prec.delta \sim Gamma(0.5, 0.0005)$$
$$prec.sigma \sim Gamma(0.5, 0.0005)$$

Since in the log crime rate income plot, we saw that there might be two trends, one where log crime rate goes down as income increases in areas with high percentage of people of color, the other where log crime rate goes up as income increases in predominantly white areas

```{r, cache=TRUE}
#Data
Model_Data.1 = Model_Data %>% filter(racegr==1)
Model_Data.2 = Model_Data %>% filter(racegr==2)
Model_Data.3 = Model_Data %>% filter(racegr==3)
data.1 = list(y=Model_Data.1$total, n=Model_Data.1$total_population, time=Model_Data.1$Year, income=Model_Data.1$per_capita_income, zipid=Model_Data.1$id, ns=length(Model_Data.1$total),nzip=unique(Model_Data.1$id))
data.2 = list(y=Model_Data.2$total, n=Model_Data.2$total_population, time=Model_Data.2$Year, income=Model_Data.2$per_capita_income, zipid=Model_Data.2$id, ns=length(Model_Data.2$total),nzip=unique(Model_Data.2$id))
data.3 = list(y=Model_Data.3$total, n=Model_Data.3$total_population, time=Model_Data.3$Year, income=Model_Data.3$per_capita_income, zipid=Model_Data.3$id, ns=length(Model_Data.3$total),nzip=unique(Model_Data.3$id))
```

```{r, cache=TRUE, message=FALSE, warning=FALSE}
#Specify the model
crime_model_3 <- "model{
    #Data
    for(i in 1:ns) {
      y[i] ~ dbin(p[i], n[i])
      logit(p[i]) = u[zipid[i]] + delta[zipid[i]]*time[i] + sigma*income[i]
    }
    
    #Priors
    sigma ~ dnorm(0, 0.0001)
    for(j in nzip){
      delta[j] ~ dnorm(0, prec.delta)
      u[j] ~ dnorm(0, prec.u)
    }

    #Hyperpriors
    prec.delta ~ dgamma(0.5, 0.0005)
    prec.u ~ dgamma(0.5, 0.0005)
    
}"

#set up an algorithm to simulate the posterior by 
#combining the model (nba_model) and data (y)
#set the random number seed
crime_jags_3.1 <- jags.model(textConnection(crime_model_3), data=data.1,
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))
crime_jags_3.2 <- jags.model(textConnection(crime_model_3), data=data.2,
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))
crime_jags_3.3 <- jags.model(textConnection(crime_model_3), data=data.3,
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))


#simulate a sample from the posterior 
#note that we specify both mu and tau variables
update(crime_jags_3.1, 10000)
update(crime_jags_3.2, 10000)
update(crime_jags_3.3, 10000)
crime_sim_3.1 <- coda.samples(crime_jags_3.1, variable.names=c("delta","sigma", "prec.delta", "u","prec.u"), n.iter=30000)
crime_sim_3.2 <- coda.samples(crime_jags_3.2, variable.names=c("delta","sigma", "prec.delta","u","prec.u"), n.iter=30000)
crime_sim_3.3 <- coda.samples(crime_jags_3.3, variable.names=c("delta","sigma", "prec.delta", "u","prec.u"), n.iter=30000)


#store the samples in a data frame:    
crime_data_3.1 <- data.frame(crime_sim_3.1[[1]])
crime_data_3.2 <- data.frame(crime_sim_3.2[[1]])
crime_data_3.3 <- data.frame(crime_sim_3.3[[1]])
```

**Check for convergence**
```{r}
running_mean_plot(crime_data_3.1$delta.4.)
running_mean_plot(crime_data_3.1$sigma)
running_mean_plot(crime_data_3.1$prec.delta)
```

```{r}
summary(crime_sim_3.1)
summary(crime_sim_3.2)
summary(crime_sim_3.3)
```

The random intercepts are all about zero for every zipcode. 
## Crime Model 3 Visualizations

```{r}
crime_viz_3_sigma <- rbind(data.frame(id=unique(Model_Data.1$zip), sigma=mean(crime_data_3.1$sigma)), 
                           data.frame(id=unique(Model_Data.2$zip), sigma=mean(crime_data_3.2$sigma)),
                           data.frame(id=unique(Model_Data.3$zip), sigma=mean(crime_data_3.3$sigma)))
zip <- readOGR(dsn="Boundaries - ZIP Codes", layer="geo_export_e1262361-5c82-45ee-8427-ef228e06dc4a")
zip_df <- fortify(zip, region = "zip")
crime_model_3_sigma <- left_join(zip_df, crime_viz_3_sigma, by="id")
head(crime_model_3_sigma)
```

### Income Differential Growth by Zipcode (Using Model 3)
```{r}
model_3_map <- ggplot() 
model_3_map <- model_3_map +  geom_polygon(data = crime_model_3_sigma, aes(x=long, y=lat, group=group, fill=sigma), color = "black", size=0.2) 
model_3_map <- model_3_map + coord_map() 
model_3_map <- model_3_map + labs(x="", y="", title=paste("Crime Rate Differential Growth by Income by Zipcode"), fill="total")
model_3_map <- model_3_map
print(model_3_map)
```

Crime rate relationship with income level is different depending on the demographic compostion of the location.

------------------------------------------------------------------------


# Police Traffic Stops model

### Cleaning the data
#### Data frame for the total population by race and zipcode
```{r}
#Number of zipcodes: 62; Number of races: 7
Police <- read.csv("Police_stops_2016_2017_sample.csv")

Police.r <- Police %>%
  filter(!(RACE_CODE_CD=="I" | RACE_CODE_CD=="P" | RACE_CODE_CD=="WHI") ) %>%
  mutate(RACE_CODE_CD = as.character(RACE_CODE_CD)) %>%
  mutate(RACE_CODE_CD=replace(RACE_CODE_CD, RACE_CODE_CD=="WWH", "HISPANIC"))

vars = c("percent_white","percent_black","percent_asian","percent_hispanic")
Population.race <- Model_Data %>%
  mutate_at(vars, function(x){trunc(Model_Data$total_population*x/100)}) %>%
  select(zip, percent_asian,percent_black,percent_hispanic, percent_white) %>%
  unique() %>%
  remove_rownames %>%
  column_to_rownames(var='zip')
head(Population.race)
```

#### Data frame for the number of arrests by zipcode and race
```{r}
valid_zips <- unique(rownames(Population.race))
Arrests <- Police.r %>% 
  filter(ZIP_CD %in% valid_zips) %>%
  group_by(ZIP_CD, RACE_CODE_CD) %>%
  dplyr::summarise(total.arrest = as.integer(sum(ENFORCEMENT_ACTION_TAKEN_I))) %>%
  spread(key=ZIP_CD, value=total.arrest) %>%
  as.data.frame() %>%
  remove_rownames %>%
  column_to_rownames(var='RACE_CODE_CD')
Arrests[is.na(Arrests)] <- as.integer(0)
head(Arrests)
```

#### Data frame for the number of police stops by zipcode and race
```{r}
Stops <- Police.r %>%
  filter(ZIP_CD %in% valid_zips) %>%
  group_by(ZIP_CD, RACE_CODE_CD) %>%
  dplyr::summarise(total.stop = n()) %>%
  spread(key=ZIP_CD, value=total.stop) %>%
  as.data.frame() %>%
  remove_rownames %>%
  column_to_rownames(var='RACE_CODE_CD')
Stops[is.na(Stops)] <- 0
head(Stops)
```

-----------------------------------------------------------------

### Preliminary visualizations

#### Stop Rate by Race
```{r}
total_pop <- Model_Data %>% filter(Year==2010) %>% select(total_population)
population_by_ethnic <- Model_Data %>%
  filter(Year==2010) %>%
  mutate_at(c("percent_asian", "percent_black", "percent_hispanic", "percent_white"), function(x){x* total_pop$total_population/100}) %>%
  mutate(zip = as.numeric(zip)) %>%
  select(percent_asian, percent_black, percent_hispanic, percent_white, zip)
population_by_ethnic
print(colSums(population_by_ethnic))
data_stops = data.frame(race=c("Asian Pacific Islander", "Black", "Hispanic", "White"), stop_rate=(rowSums(Stops)/colSums(population_by_ethnic %>% select(-zip))))
rownames(data_stops) <- c()
head(data_stops %>% arrange(desc(stop_rate)))
```

Blacks and Hispanics are stopped at higher rate than Whites and Asians given their population.

### Plot of Traffic Stops by Population
```{r}
l <- population_by_ethnic %>%
  mutate(BLK=percent_black, HISPANIC=percent_hispanic, API=percent_asian, WHT=percent_white) %>%
  select(BLK, HISPANIC, API, WHT, zip) %>%
  gather(key=RACE_CODE_CD, value=population, - zip)

data <- Police.r %>%
  filter(ZIP_CD %in% valid_zips) %>%
  group_by(ZIP_CD, RACE_CODE_CD) %>%
  dplyr::summarise(total.stop = n()) %>%
  inner_join(l, by=c("ZIP_CD" = 'zip', 'RACE_CODE_CD')) %>%
  mutate(race=RACE_CODE_CD)

ggplot(data, aes(x=population, y=total.stop, colour=RACE_CODE_CD)) + geom_point() + geom_smooth() +
  labs(x="Population Count", y="Number of Traffic Stops", title="Traffic Stops By Population", subtitle="Visualization of number of traffic stops as the population of each ethnic group increases for each zipcode") + 
  guides(colour=guide_legend("Race")) +
  theme(plot.title = element_text(hjust=0.5)) 
```

### Plot of Traffic Stops by Percentage of Population
```{r}
ggplot(data, aes(x=population, y=total.stop, colour=RACE_CODE_CD)) + geom_point() + geom_smooth() +
  labs(x="Percent of Population", y="Number of Traffic Stops", fill="Race", title="Traffic Stops By Percentage of Population") + 
  guides(colour=guide_legend("Race")) +
  theme(plot.title = element_text(hjust=0.5))
```

------------------------------------------------------------


## Police Model 0

### Variables Used

- Data is only from January 2016 - February 2017 (13/12)

- i: ethnic group

- j: zipcode locations in Chicago

- y[i, j]: observed number of arrests of ethnic group i in area j

- n[i, j]: the number of traffic stops in area j for ethnic group i

- $\mu$: grand mean of arrests

- $\alpha$[i]: the random effect for each ethnic group i


#### Data 
$$y_{ij} \sim Pois(\frac{13}{12} n_{ij}  \theta_{ij})$$
$$log(\theta_{ij}) = \mu + \alpha_{i} $$

#### Priors
$$\mu \sim N(0, 0.000001)$$
$$\alpha_{i} \sim N(0, 0.000001)$$


```{r}
log(0.28603)
log(0.28603+0.05911) - log(0.28603)
log(0.28603-0.05712) - log(0.28603)
log(0.28603-0.12381) - log(0.28603)
```

```{r, cache=TRUE, message=FALSE, warning=FALSE}
police_model_0 <- "model{
  #Data
  for (i in 1:4) {
    for(j in 1:58){
      y[i,j] ~ dpois((13/12) * n[i,j] * theta[i,j])
      log(theta[i,j]) <- mu + alpha[i]
    }
  }

  #Priors
  mu ~ dnorm(0, 1.0E-06)

  for (i in 1:4){
    alpha[i] ~ dnorm(0, 0.005)
  }
}"

#initial value set
inits = list(mu=-1.251659, alpha=c(0, 0.1878534, -0.2227678, -0.5671433))

police_jags_0 <- jags.model(textConnection(police_model_0), data=list(y=Arrests, n=Stops),
                    inits=inits)

#simulate a sample from the posterior 
#note that we specify both mu and tau variables
police_sim_0 <- coda.samples(police_jags_0, variable.names=c("mu", "alpha"), n.iter=400000)

#store the samples in a data frame:    
police_data_0 <- data.frame(step=1:400000, police_sim_0[[1]])
```

```{r}
running_mean_plot(police_data_0$mu)
running_mean_plot(police_data_0$alpha.2.)
```

------------------------------------------------------------------

## Police Model 1

```{r}
#estimate initial values
data <- Police.r %>% 
  filter(ZIP_CD %in% valid_zips) %>%
  group_by(ZIP_CD, RACE_CODE_CD) %>%
  dplyr::summarise(total.arrest = as.integer(sum(ENFORCEMENT_ACTION_TAKEN_I)), total.stop = n())
head(data)
```

```{r}
freq_model <- lm(total.arrest ~ RACE_CODE_CD * total.stop, data = data)
summary(freq_model)
```

### Variables Used

- Data is only from January 2016 - February 2017 (13/12)

- i: ethnic group

- j: zipcode locations in Chicago

- y[i, j]: observed number of arrests of ethnic group i in area j

- n[i, j]: the number of traffic stops in area j for ethnic group i

- $\mu$: grand mean of arrests

- $\alpha$[i]: the random effect for each ethnic group i

- $\beta$[j]: the random effect for each zipcode location j

- $\epsilon$[i, j]: the random error for each ethnic group i and location j

#### Data 
$$y_{ij} \sim Pois(\frac{13}{12} n_{ij}  \theta_{ij})$$
$$log(\theta_{ij}) = \mu + \alpha_{i} + \beta_{j} + \epsilon_{ij}$$

#### Priors
$$\beta_{0} \sim N(0, 0.000001)$$
$$\alpha_{i} \sim N(0, 0.000001)$$
$$\beta_{j} \sim N(0, b^2)$$
$$\epsilon_{ij} \sim N(0, e^2)$$

#### Hyperpriors
$$b \sim Gamma(0.5, 0.0005)$$
$$e \sim Gamma(0.5, 0.0005)$$

```{r, cache=TRUE, message=FALSE, warning=FALSE}
police_model_1 <- "model{
  #Data
  for (i in 1:4) {
    for(j in 1:58){
      y[i,j] ~ dpois((13/12)*n[i,j]*theta[i,j])
      log(theta[i,j]) <- mu + alpha[i] + beta[j] + epsilon[i,j]
    }
  }

  #Priors

  mu ~ dnorm(0,1.0E-06)

  for (i in 1:4){
    alpha[i] ~ dnorm(0, 0.005)
  }

  for (j in 1:58){
    beta[j] ~ dnorm(0, 1/b^2)
  }

  for (i in 1:4){
    for (j in 1:58){
      epsilon[i,j] ~ dnorm(0, 1/e^2)
    }
  }

  b ~ dgamma(0.5, 0.0005)
  e ~ dgamma(0.5, 0.0005)
  
}"

#initial value set
inits = list(mu=-1.251659, alpha=c(0, 0.1878534, -0.2227678, -0.5671433), tau_beta=170, tau_epsilon=170, beta=rep(0.03, 58), epsilon=matrix(rep(0.01, 58*4), ncol=58))

police_jags_1 <- jags.model(textConnection(police_model_1), data=list(y=Arrests, n=Stops),
                    inits=inits)

#simulate a sample from the posterior 
#note that we specify both mu and tau variables
police_sim_1 <- coda.samples(police_jags_1, variable.names=c("mu", "alpha", "beta", "b", "e", "epsilon"), n.iter=500000)

#store the samples in a data frame:    
police_data_1 <- data.frame(step=1:500000, police_sim_1[[1]])
```

### Running mean plot of beta.1., mu, and alpha.2.
```{r}
running_mean_plot(police_data_1$beta.1.)
running_mean_plot(police_data_1$mu)
running_mean_plot(police_data_1$alpha.2.)
```


```{r}
police_viz <- police_data_1 %>%
  colMeans() %>%
  as.data.frame() %>%
  rownames_to_column(var="zipcode") %>%
  setNames(., c("zipcode", "beta")) %>%
  filter(grepl("beta", zipcode)) %>%
  mutate(zipcode = as.integer(gsub("\\D", "", zipcode))) %>%
  mutate(mu = mean(police_data_1$mu)) %>%
  mutate(rate = exp(mu + beta)) %>%
  left_join(zip_data, by="zipcode") %>%
  mutate(id=as.character(zip))
police_model_beta <- left_join(zip_df, police_viz, by="id")
head(police_model_beta)
```

### Map of rate at which traffic stops result in arrests by zipcode (Using Model 3)
```{r}
model_1_map_beta <- ggplot() 
model_1_map_beta <- model_1_map_beta +  geom_polygon(data = police_model_beta, aes(x=long, y=lat, group=group, fill=rate), color = "black", size=0.2) 
model_1_map_beta <- model_1_map_beta + coord_map() 
model_1_map_beta <- model_1_map_beta + labs(x="", y="", title=paste("Rate at Which Traffic Stops Result in Arrests by Zipcode"), fill="total")
model_1_map_beta <- model_1_map_beta + cleanup
print(model_1_map_beta)
```

### Rate of traffic stops by ethnic group
```{r}
police_viz1 <- police_data_1 %>%
  colMeans() %>%
  as.data.frame() %>%
  rownames_to_column(var="zipcode") %>%
  setNames(., c("zipcode", "alpha")) %>%
  filter(grepl("alpha", zipcode)) %>%
  mutate(mu = mean(police_data_1$mu)) %>%
  mutate(rate = exp(mu + alpha))
head(police_viz1)
```

