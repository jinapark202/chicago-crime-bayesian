---
title: "Examining Crime Hotspots in Chicago Using Bayesian Statistics"
author: "Jina Park, Phuc Nguyen"
date: "12/7/2017"
output: html_document
---

### Motivation

**Provide a clear description of your project goals. Provide a brief description and citations for existing literature on this topic (or the other resources that inspired this project).**

Chicago currently leads the United States with the greatest number of homicides and violent crimes. In 2016, the number of homicides in Chicago increased 58% from the year before (Ford, 2017). Using police data from the City of Chicago's Data Portal, we examine crime hot spots in Chicago and whether crime rates differ by geographic and demographic information. In addition, we examine the hot spots for violent and non-violent crimes. Understanding crime hot spots proves advantageous to law enforcement as they can enact hot spot policing measures and other resources to reduce crime in these particular areas (Law, et al. 2014). In particular, the Bayesian approach can be used to predict changes in hot spots and crime rates over time. 

##### Literature Review 

Law, et al. (2014) identifies hot spots and overall trends of violent crime in the Greater Toronto Area using a Bayesian spatiotemporal modeling approach. Although frequentists define hot spots as areas with high crime rates that are also surrounded by other high-crime areas for one time period, Bayesian statistics allow us to examine how hot spots change over time (Law, et al. 2014). For this reason, we apply Bayesian methods to examine how hot spots in Chicago change year over year. 



### Methods and Results

**Discuss your methodology in detail (e.g. the structure of your Bayesian model, your prior/posterior understanding, your Markov chain algorithm).**

Although Chicago is widely known for its high level of violent crime, certain areas of Chicago are prone to more crime than others. In Figure 1 below, the concentration of crime in Chicago is particularly high in the areas highlighted in red. To add further, the concentration of hot spots shifts slighly from 2010 to 2016, with greater crime rates in northeast Chicago in 2016 compared to 2010. 

```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# Load Library
library(tidyr)
library(rjags)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(MacBayes)
library(choroplethrZip)
library(rgdal)
library(devtools)
library(choroplethr)
library(choroplethrMaps)
library(mapproj)
library(grid)
library(gridExtra)

#install.packages("devtools")
#install_github('arilamstein/choroplethrZip@v1.5.0')
```

```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# Load data
Crime <- read.csv("Crime.csv")
Model_Data <- read.csv("Crime_models_data.csv")
Model_Data_Violent <- read.csv("Crime_models_violent_data.csv")
Model_Data_Nviolent <- read.csv("Crime_models_nonviolent_data.csv")
```

```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# Map cleanup 
cleanup <- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = 'white', colour = 'white'),
        axis.line = element_line(colour = "white"),
        axis.ticks=element_blank(), axis.text.x=element_blank(),
        axis.text.y=element_blank())
```

```{r, include=FALSE, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE}
towntracts <- readOGR(dsn="chicago_tracts_2010", layer="geo_export_9588a35d-8dfa-4dd9-9d49-6cdfc941d52b")
```

```{r, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE}
Crime_2010 <- Crime %>% filter(Year == 2010)
gg2010 <- ggplot()
gg2010 <- gg2010 + geom_polygon(data=towntracts, aes(x=long, y=lat, group=group), colour="black", fill="grey90", size=0.5) 
gg2010 <- gg2010 + stat_density2d(data=Crime_2010, show.legend=F, aes(x=Longitude, y=Latitude, fill=..level.., alpha=..level..), geom="polygon", size=2, bins=10)
gg2010 <- gg2010 + scale_fill_gradient(low="deepskyblue2", high="firebrick1", name="Distribution")
gg2010 <- gg2010 +  coord_map("polyconic")
gg2010 <- gg2010 + labs(x=NULL, y=NULL,
                  subtitle=NULL,
                  caption="2010")
gg2010 <- gg2010 + cleanup + theme(plot.margin = unit(c(0,0,0,0), "lines"))

Crime_2013 <- Crime %>% filter(Year == 2013)
gg2013 <- ggplot()
gg2013 <- gg2013 + geom_polygon(data=towntracts, aes(x=long, y=lat, group=group), colour="black", fill="grey90", size=0.5) 
gg2013 <- gg2013 + stat_density2d(data=Crime_2013, show.legend=F, aes(x=Longitude, y=Latitude, fill=..level.., alpha=..level..), geom="polygon", size=2, bins=10)
gg2013 <- gg2013 + scale_fill_gradient(low="deepskyblue2", high="firebrick1", name="Distribution")
gg2013 <- gg2013 +  coord_map("polyconic")
gg2013 <- gg2013 + labs(x=NULL, y=NULL,
                  subtitle=NULL,
                  caption="2013")
gg2013 <- gg2013 + cleanup + theme(plot.margin = unit(c(0,0,0,0), "lines"))


Crime_2016 <- Crime %>% filter(Year == 2016)
gg2016 <- ggplot()
gg2016 <- gg2016 + geom_polygon(data=towntracts, aes(x=long, y=lat, group=group), colour="black", fill="grey90", size=0.5) 
gg2016 <- gg2016 + stat_density2d(data=Crime_2016, show.legend=F, aes(x=Longitude, y=Latitude, fill=..level.., alpha=..level..), geom="polygon", size=2, bins=10)
gg2016 <- gg2016 + scale_fill_gradient(low="deepskyblue2", high="firebrick1", name="Distribution")
gg2016 <- gg2016 +  coord_map("polyconic")
gg2016 <- gg2016 + labs(x=NULL, y=NULL,
                  subtitle=NULL,
                  caption="2016")
gg2016 <- gg2016 + cleanup + theme(plot.margin = unit(c(0,0,0,0), "lines"))

grid.arrange(gg2010, gg2013, gg2016, ncol=3, top=textGrob("Concentration of Crime in Chicago"))
```

```{r, include=FALSE, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE}
data(df_pop_zip)
data(df_zip_demographics)

zip_percent_white <- df_zip_demographics[c("region", "percent_white")]
colnames(zip_percent_white)[2] <- "value"

zip_percent_black <- df_zip_demographics[c("region", "percent_black")]
colnames(zip_percent_black)[2] <- "value"

zip_percent_asian <- df_zip_demographics[c("region", "percent_asian")]
colnames(zip_percent_asian)[2] <- "value"

zip_percent_hispanic <- df_zip_demographics[c("region", "percent_hispanic")]
colnames(zip_percent_hispanic)[2] <- "value"

zip_per_capita_income <- df_zip_demographics[c("region", "per_capita_income")]
colnames(zip_per_capita_income)[2] <- "value"

zip_median_rent <- df_zip_demographics[c("region", "median_rent")]
colnames(zip_median_rent)[2] <- "value"

zip_median_age <- df_zip_demographics[c("region", "median_age")]
colnames(zip_median_age)[2] <- "value"

data(zip.regions)
chi_nap_elg <- subset(zip.regions, zip.regions$cbsa.title=="Chicago-Naperville-Elgin, IL-IN-WI")
cook_county <- subset(chi_nap_elg, chi_nap_elg$county.name == "cook")
cook_fips <- cook_county$county.fips.numeric
```


The maps below highlight the significant demographic differences across different zipcodes in Chicago. While per capita income appears positively related with both the Asian and White populations in Chicago, it appears negatively related with the Hispanic and Black populations. Since crime rates might differ between both race and income groups, we take these demographics into consideration when predicting hot spots in Chicago.

```{r, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE, fig.width=15, fig.height=15, fig.align="center"}
pop_map <- zip_choropleth(df_pop_zip, 
               county_zoom = cook_fips, 
               title="Total Population") + coord_map()

white_pop_map <- zip_choropleth(zip_percent_white, 
               county_zoom = cook_fips, 
               title="White Population") + coord_map()

black_pop_map <- zip_choropleth(zip_percent_black, 
               county_zoom = cook_fips, 
               title="Black Population") + coord_map()

asian_pop_map <- zip_choropleth(zip_percent_asian, 
               county_zoom = cook_fips, 
               title="Asian Population") + coord_map()

hisp_pop_map <- zip_choropleth(zip_percent_hispanic, 
               county_zoom = cook_fips, 
               title="Hispanic Population") + coord_map()

income_map <- zip_choropleth(zip_per_capita_income, 
               county_zoom = cook_fips, 
               title="Per Capita Income") + coord_map()

rent_map <- zip_choropleth(zip_median_rent, 
               county_zoom = cook_fips, 
               title="Median Rent") + coord_map()

age_map <- zip_choropleth(zip_median_age, 
               county_zoom = cook_fips, 
               title="Median Age") + coord_map()

grid.arrange(pop_map, white_pop_map, black_pop_map, asian_pop_map, hisp_pop_map, income_map, rent_map, age_map, ncol=3, top="Demographic Maps of Chicago by Zipcode")
```

###### Talk about data and the methods used

For this research, we obtained our data from the City of Chicago's Data Portal. We filter for crimes occurred between 2010-2017 where each row represents a crime observation in Chicago. In addition, we standardized the values for year and income to make our models easier to interpret and converge. We then focused on the following variables for our analysis: time, type of crime, and location.

To derive our models, we used the Gibbs sampler. We checked for convergence of our models using running mean plots and the Gailman measure.

###### Overview of Models

Figure 3 plots the relationship between the log of the crime rate and year for zipcodes in Chicago. It shows a slight downward trend in the log of crime rates as the years increase. Since it is possible that overall crime rates might have a negative, linear trend over time, we incorporate a time trend in our models.

```{r, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE, fig.width=15, fig.height=15, fig.align="center"}
Crime_count <- Model_Data %>%
  select(Year, zip, total) %>%
  spread(key=Year, value=total)
rownames(Crime_count) <- Crime_count$zip 
Crime_count <- Crime_count %>% select(-zip)
Crime_count[is.na(Crime_count)] <- 0

Population <- Model_Data %>%
  select(total_population, zip, Year) %>%
  spread(key=Year, value=total_population) %>%
  select('2010', zip)
rownames(Population) <- Population$zip
Population <- Population %>% select(-zip)
Population[is.na(Population)] <- 0
Population.vector <- Population$`2010`

Crime_count_log_calc <- log(Crime_count/Population.vector)
Crime_count_log <- Crime_count_log_calc %>%
  rownames_to_column() %>%
  gather(key=year, value=crime_count_log, -rowname) %>%
  mutate(zip=rowname) %>%
  select(zip, year, crime_count_log) %>%
  mutate(year=as.numeric(year))

ggplot(Crime_count_log, aes(x=year, y=crime_count_log, colour=zip)) + geom_point() + geom_line() + labs(title="Crime Rate Over Time", y="Log of Crime Rate", x="Year", color="Zipcodes")
```

##### Model 1

In our first model, we predict crime hot spots in Chicago is a simple model that incorporates a time trend.

$$y_{ij} \sim Bin(n_{ij}, p_{ij})$$
$$log(\frac{p_{ij}}{1-p_{ij}}) = \beta_{i} + \delta_{i}* time_{j}$$
$$\beta_{i} \sim N(0, \tau_{0})$$
$$\delta_{i} \sim N(0, \tau_{1})$$
$$\tau_{0,1} \sim Gamma(0.5, 0.0005)$$

In this model, $y_{ij}$ is the observed crime count in zipcode $i$ and year $j$, where $p_{ij}$ is the probability of a person being involved in a crime and $n_{ij}$ represents the total population. It is modeled with a Binomial distribution because a person is either involved in a crime incident or not involved in a crime incident. 

$log(\frac{p_{ij}}{1-p_{ij}})$ represents the log odds of the inherent crime rate in zipcode $i$ and year $j$. The log odds is a function of $\beta_{i}$, which is the intercept for each zipcode $i$ in Chicago, $\delta_{i}$, the crime differential growth over time in zipcode $i$, and time.

The prior distributions of $\beta$ and $\sigma$ are normally distributed with a mean of zero and a precision of $\tau$. $\tau$, which is modeled with a Gamma distribution, has a standard deviation of roughly 63. This signifies that $\tau$ is a vague prior given that the grand mean of $\beta_{i}$ and $\delta_{i}$ are approximately -7.45 and -0.065.

```{r, include=FALSE, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE}
#Data
data = list(y=Model_Data$total, n=Model_Data$total_population, time=Model_Data$time, zipid=Model_Data$id, ns=length(Model_Data$total), nzip=length(unique(Model_Data$id)))

#Specify the model
crime_model_1 <- "model{
    #Data
    for(i in 1:ns) {
      y[i] ~ dbin(p[i], n[i])
      logit(p[i]) = beta[zipid[i]] + delta[zipid[i]]*time[i]
    }
    
    #Priors
    for(j in 1:nzip){
      delta[j] ~ dnorm(0, tau_1)
      beta[j] ~ dnorm(0, tau_0)
    }

    #Hyperpriors
    tau_0 ~ dgamma(0.5, 0.0005)
    tau_1 ~ dgamma(0.5, 0.0005)
    
}"

#set up an algorithm to simulate the posterior
#set the random number seed
init.rng1<-list(".RNG.seed" = 1998, ".RNG.name" = "base::Mersenne-Twister")
crime_jags_1 <- jags.model(textConnection(crime_model_1), data=data,
                    inits=init.rng1)


#simulate a sample from the posterior 
crime_sim_1 <- coda.samples(crime_jags_1, variable.names=c("delta", "beta", "tau_0", "tau_1"), n.iter=30000)


#store the samples in a data frame:    
crime_data_1 <- data.frame( crime_sim_1[[1]])
```

```{r, include=FALSE, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE}
n = length(unique(Model_Data$zip))
crime_model_1_mean <- matrix(nrow=n, ncol=1)
for (i in 1:n) {
      crime_model_1_mean[i, ] <- mean(crime_data_1[[i+n]])
}

zip <- readOGR(dsn="Boundaries - ZIP Codes", layer="geo_export_e1262361-5c82-45ee-8427-ef228e06dc4a")
zip_df <- fortify(zip, region = "zip")
crime_model_1_delta <- left_join(zip_df, data.frame(id=as.character(unique(Model_Data$zip)), delta=crime_model_1_mean), by='id')
```

```{r, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE}
model_1_map <- ggplot() 
model_1_map <- model_1_map +  geom_polygon(data = crime_model_1_delta, aes(x=long, y=lat, group=group, fill=delta), color = "black", size=0.2) 
model_1_map <- model_1_map + coord_map() 
model_1_map <- model_1_map + labs(x="", y="", title=paste("Crime Differential Growth by Zipcode"), caption="Model 1", fill="Trend over Time")
model_1_map <- model_1_map + cleanup + scale_fill_gradient(low = "blue", high = "orange")
print(model_1_map)
```

Chicago is particularly well-known for its high level of violent crime including homicides. In fact, in 2016, the number of homicides in Chicago increased 58% from the previous year. For this reason, we divided our data into two groups, violent and non-violent crimes, to examine whether hot spots of violent crimes differ from hot spots of non-violent crimes. We classified the following types of crime as 'violent': robbery, battery, burglary, assault, homicide, sex offense, criminal sexual assault, and arson. All other crime types in our data are considered 'non-violent'. 

```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE, comment=NA}
#Data
data = list(y=Model_Data_Violent$total, n=Model_Data_Violent$total_population, time=Model_Data_Violent$time, zipid=Model_Data_Violent$id, ns=length(Model_Data_Violent$total), nzip=length(unique(Model_Data_Violent$id)))

data.NV = list(y=Model_Data_Nviolent$total, n=Model_Data_Nviolent$total_population, time=Model_Data_Nviolent$time, zipid=Model_Data_Nviolent$id, ns=length(Model_Data_Nviolent$total), nzip=length(unique(Model_Data_Nviolent$id)))
```

```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE, comment=NA}
#Specify the model
crime_model_1 <- "model{
    #Data
    for(i in 1:ns) {
      y[i] ~ dbin(p[i], n[i])
      logit(p[i]) = beta[zipid[i]] + delta[zipid[i]]*time[i]
    }
    
    #Priors
    for(j in 1:nzip){
      delta[j] ~ dnorm(0, tau_1)
      beta[j] ~ dnorm(0, tau_0)
    }

    #Hyperpriors
    tau_0 ~ dgamma(0.5, 0.0005)
    tau_1 ~ dgamma(0.5, 0.0005)
    
}"

#set up an algorithm to simulate the posterior
#set the random number seed
init.rng1<-list(".RNG.seed" = 1998, ".RNG.name" = "base::Mersenne-Twister")
crimeV_jags_1 <- jags.model(textConnection(crime_model_1), data=data,
                    inits=init.rng1)
crimeNV_jags_1 <- jags.model(textConnection(crime_model_1), data=data.NV,
                    inits=init.rng1)


#simulate a sample from the posterior 
crimeV_sim_1 <- coda.samples(crimeV_jags_1, variable.names=c("delta", "beta", "tau_0", "tau_1"), n.iter=30000)

crimeNV_sim_1 <- coda.samples(crimeNV_jags_1, variable.names=c("delta", "beta", "tau_0", "tau_1"), n.iter=30000)


#store the samples in a data frame:    
crimeV_data_1 <- data.frame( crimeV_sim_1[[1]])
crimeNV_data_1 <- data.frame( crimeNV_sim_1[[1]])
```

```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE, comment=NA}
n = length(unique(Model_Data_Violent$zip))
n = length(unique(Model_Data_Nviolent$zip))

crimeV_model_1_mean <- matrix(nrow=n, ncol=1)
for (i in 1:n) {
      crimeV_model_1_mean[i, ] <- mean(crimeV_data_1[[i+n]])
}

crimeNV_model_1_mean <- matrix(nrow=n, ncol=1)
for (i in 1:n) {
      crimeNV_model_1_mean[i, ] <- mean(crimeNV_data_1[[i+n]])
}
```

```{r, , fig.width=15, fig.height=15, fig.align="center", include=FALSE, message=FALSE, warning=FALSE, echo=FALSE, comment=NA}
zip <- readOGR(dsn="Boundaries - ZIP Codes", layer="geo_export_e1262361-5c82-45ee-8427-ef228e06dc4a")
zip_df <- fortify(zip, region = "zip")
crimeV_model_1_delta <- left_join(zip_df, data.frame(id=as.character(unique(Model_Data_Violent$zip)), delta=crimeV_model_1_mean), by='id')

zip <- readOGR(dsn="Boundaries - ZIP Codes", layer="geo_export_e1262361-5c82-45ee-8427-ef228e06dc4a")
zip_df <- fortify(zip, region = "zip")
crimeNV_model_1_delta <- left_join(zip_df, data.frame(id=as.character(unique(Model_Data_Nviolent$zip)), delta=crimeNV_model_1_mean), by='id')
```

```{r, message=FALSE, warning=FALSE, echo=FALSE, comment=NA}
model_1_map_v <- ggplot() 
model_1_map_v <- model_1_map_v +  geom_polygon(data = crimeV_model_1_delta, aes(x=long, y=lat, group=group, fill=delta), color = "black", size=0.2) 
model_1_map_v <- model_1_map_v + coord_map() 
model_1_map_v <- model_1_map_v + labs(x="", y="", title=paste("Violent Crime Differential Growth by Zipcode"), fill="Trend over Time", caption="Model 1")
model_1_map_v <- model_1_map_v + cleanup + scale_fill_gradient(low = "blue", high = "orange")
```


```{r, message=FALSE, warning=FALSE, echo=FALSE, comment=NA, fig.width=15, fig.height=15, fig.align="center"}
model_1_map_nv <- ggplot() 
model_1_map_nv <- model_1_map_nv +  geom_polygon(data = crimeNV_model_1_delta, aes(x=long, y=lat, group=group, fill=delta), color = "black", size=0.2) 
model_1_map_nv <- model_1_map_nv + coord_map() 
model_1_map_nv <- model_1_map_nv + labs(x="", y="", title=paste("Non-Violent Crime Differential Growth by Zipcode"), fill="Trend over Time", caption="Model 1")
model_1_map_nv <- model_1_map_nv + cleanup + scale_fill_gradient(low = "blue", high = "orange")

grid.arrange(model_1_map_v, model_1_map_nv, ncol=2)
```

The map of violent crimes shows greater areas of increasing crime differential growth compared to non-violent crimes over time. This suggests that overall, violent crimes are increasing in Chicago more than non-violent crimes. However, in general, it appears that many areas of Chicago are facing lower crime, both violent and non-violent, with time.

##### Model 2

In our second model, we examine changes in the crime rate while taking into account differences in race and income levels in specific areas.

$$y_{i} \sim Bin(n_{i}, p_{i})$$

$$log(\frac{p_{i}}{1-p_{i}}) = \beta_{i} + \delta_{i} * time_{j} + \sum_{e=1}^{5} \sigma_{e} * income_{i} * perwhite_{e}$$

$$\beta_{i} \sim N(0, \tau_{0})$$
$$\delta_{i} \sim N(0, \tau_{1})$$

$$\sigma_{e} \ sim N(0, \tau_{2})$$
$$\tau_{0,1,2} \sim Gamma(0.5, 0.0005)$$
- Add graph with income and race and nonwhite percentage (Simpson's Paradox -- Model 3) -> reason for interaction term.

In Figure 2, we plotted the log of per capita income vs the log of the crime rate by the non-white percentage in each zipcode. In areas with large white populations, an increase in the per capita income seems to increase the crime rate. However, when an area has a greater non-white population, the crime rate seems to fall as per capita income increases. Figure 2 seems to suggest that the relationship between income and crime differs depending on an area's demographic population. For this reason, we derived Model 2 by taking into consideration income and percentage of white people in each area.

```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE, comment=NA}
Crime_count_log <- Model_Data %>%
  mutate(log_rate = log(total/total_population)) %>%
  select(zip, Year, log_rate)

Model_Data_1 <- Model_Data %>%
  filter(Year == 2010) %>%
  mutate(percent_nonwhite = 100 - percent_white) %>%
  select(zip, per_capita_income, percent_nonwhite) %>%
  right_join(Crime_count_log, by="zip") 
```

```{r, message=FALSE, warning=FALSE, echo=FALSE, comment=NA}
ggplot(Model_Data_1, aes(x=log(per_capita_income), y=log_rate, colour=percent_nonwhite)) + geom_point() + labs(x="Log of Per Capita Income", y="Log of Crime Rate", title="Relationship between Per Capita Income and Crime Rate", color="Nonwhite Percentage") 
```

- Talk about groupings of race

- Add maps
```{r, include=FALSE, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
Model2_Data <- Model_Data 
data = list(y=Model2_Data$total, n=Model2_Data$total_population, time=Model2_Data$time, zipid=Model2_Data$id, racegr=Model2_Data$racegr, income=Model2_Data$income, ns=nrow(Model2_Data), nzip=length(unique(Model2_Data$zip)))

#Specify the model
crime_model_2 <- "model{
    #Data
    for(i in 1:ns) {
      y[i] ~ dbin(p[i], n[i])
      logit(p[i]) = beta[racegr[i]] + delta[racegr[i]]*time[i] + sigma[racegr[i]]*income[i] 
    }
    
    #Priors
    for(j in 1:5){
      sigma[j] ~ dnorm(0, tau_2)
      beta[j] ~ dnorm(0, tau_0)
      delta[j] ~ dnorm(0, tau_1)

    }

    #Hyperpriors
    tau_0 ~ dgamma(0.5, 0.0005)
    tau_1 ~ dgamma(0.5, 0.0005)
    tau_2 ~ dgamma(0.5, 0.0005)
    
}"

#set up an algorithm to simulate the posterior by 
#combining the model (nba_model) and data (y)
#set the random number seeds
crime_jags_2 <- jags.model(textConnection(crime_model_2), data=data,
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))


#simulate a sample from the posterior 
#note that we specify both mu and tau variables
crime_sim_2 <- coda.samples(crime_jags_2, variable.names=c("sigma", "tau_0", "beta","tau_1", "tau_2", "delta"), n.iter=30000, n.thin=5)

#store the samples in a data frame:    
crime_data_2 <- data.frame(crime_sim_2[[1]])
```

```{r, include=FALSE, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
posterior_means <- crime_data_2 %>% colMeans()

crime_model_2_sigma <- Model_Data
crime_model_2_sigma$beta <- recode(crime_model_2_sigma$racegr, `1`=posterior_means[1],
                                   `2`=posterior_means[2],
                                   `3`=posterior_means[3],
                                   `4`=posterior_means[4],
                                   `5`=posterior_means[5])
crime_model_2_sigma$sigma <- recode(crime_model_2_sigma$racegr, `1`=posterior_means[6],
                                   `2`=posterior_means[7],
                                   `3`=posterior_means[8],
                                   `4`=posterior_means[9],
                                   `5`=posterior_means[10])
crime_model_2_sigma <- crime_model_2_sigma %>%
  mutate(id = as.character(zip)) %>%
  right_join(zip_df, by="id")
```

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
model_2_map <- ggplot() 
model_2_map <- model_2_map +  geom_polygon(data = crime_model_2_sigma, aes(x=long, y=lat, group=group, fill=sigma), color = "black", size=0.2) 
model_2_map <- model_2_map + coord_map() 
model_2_map <- model_2_map + labs(x="", y="", title=paste("Crime Differential Growth Based on Income and Demographics"), caption="Model 2", fill="Trend over Time")
model_2_map <- model_2_map + cleanup + scale_fill_gradient(low = "blue", high = "orange")
print(model_2_map)
```

- Talk about maps

- Add maps for violent vs non-violent crimes

```{r, echo=FALSE, include=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
Model2_Data_NViolent <- Model_Data_Nviolent %>% filter(Year==2010)

Model2_Data_Violent <- Model_Data_Violent %>% filter(Year==2010)

data.v = list(y=Model2_Data_Violent$total, n=Model2_Data_Violent$total_population, racegr=Model2_Data_Violent$racegr, income=Model2_Data_Violent$income, ns=nrow(Model2_Data_Violent))

data.NV = list(y=Model2_Data_NViolent$total, n=Model2_Data_NViolent$total_population, racegr=Model2_Data_NViolent$racegr, income=Model2_Data_NViolent$income, ns=nrow(Model2_Data_NViolent))
```

```{r, echo=FALSE, include=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
#Specify the model
crime_model_2_v <- "model{
    #Data
    for(i in 1:ns) {
      y[i] ~ dbin(p[i], n[i])
      logit(p[i]) = beta[racegr[i]] + sigma[racegr[i]]*income[i]
    }
    
    #Priors
    for(j in 1:5){
      sigma[j] ~ dnorm(0, tau_1)
      beta[j] ~ dnorm(0, tau_0)
    }

    #Hyperpriors
    tau_0 ~ dgamma(0.5, 0.0005)
    tau_1 ~ dgamma(0.5, 0.0005)
    
}"

#set up an algorithm to simulate the posterior by 
#combining the model (nba_model) and data (y)
#set the random number seed
crimeV_jags_2 <- jags.model(textConnection(crime_model_2_v), data=data.v,
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))
crimeNV_jags_2 <- jags.model(textConnection(crime_model_2_v), data=data.NV,
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))


#simulate a sample from the posterior 
#note that we specify both mu and tau variables
crimeV_sim_2 <- coda.samples(crimeV_jags_2, variable.names=c("sigma", "tau_0", "beta","tau_1"), n.iter=30000, n.thin=5)
crimeNV_sim_2 <- coda.samples(crimeNV_jags_2, variable.names=c("sigma", "tau_0", "beta","tau_1"), n.iter=30000, n.thin=5)


#store the samples in a data frame:    
crimeV_data_2 <- data.frame(crimeV_sim_2[[1]])
crimeNV_data_2 <- data.frame(crimeNV_sim_2[[1]])
```

```{r, echo=FALSE, include=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
posterior_means <- crimeV_data_2 %>% colMeans()

crimeV_model_2_sigma <- Model_Data_Violent

crimeV_model_2_sigma$beta <- recode(crimeV_model_2_sigma$racegr, `1`=posterior_means[1],
                                   `2`=posterior_means[2],
                                   `3`=posterior_means[3],
                                   `4`=posterior_means[4],
                                   `5`=posterior_means[5])
crimeV_model_2_sigma$sigma <- recode(crimeV_model_2_sigma$racegr, `1`=posterior_means[6],
                                   `2`=posterior_means[7],
                                   `3`=posterior_means[8],
                                   `4`=posterior_means[9],
                                   `5`=posterior_means[10])
crimeV_model_2_sigma <- crimeV_model_2_sigma %>%
  mutate(id = as.character(zip)) %>%
  right_join(zip_df, by="id")

posterior_means <- crimeNV_data_2 %>% colMeans()

crimeNV_model_2_sigma <- Model_Data_Nviolent
crimeNV_model_2_sigma$beta <- recode(crimeNV_model_2_sigma$racegr, `1`=posterior_means[1],
                                   `2`=posterior_means[2],
                                   `3`=posterior_means[3],
                                   `4`=posterior_means[4],
                                   `5`=posterior_means[5])
crimeNV_model_2_sigma$sigma <- recode(crimeNV_model_2_sigma$racegr, `1`=posterior_means[6],
                                   `2`=posterior_means[7],
                                   `3`=posterior_means[8],
                                   `4`=posterior_means[9],
                                   `5`=posterior_means[10])
crimeNV_model_2_sigma <- crimeNV_model_2_sigma %>%
  mutate(id = as.character(zip)) %>%
  right_join(zip_df, by="id")
```

```{r, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
model_2_map_v <- ggplot() 
model_2_map_v <- model_2_map_v +  geom_polygon(data = crimeV_model_2_sigma, aes(x=long, y=lat, group=group, fill=sigma), color = "black", size=0.2) 
model_2_map_v <- model_2_map_v + coord_map() 
model_2_map_v <- model_2_map_v + labs(x="", y="", title=paste("Violent Crime Differential Growth"), fill="Trend over Time", caption="Model 2")
model_2_map_v <- model_2_map_v + cleanup + scale_fill_gradient(low = "blue", high = "orange")
```

```{r, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE, fig.width=15, fig.height=15, fig.align="center"}
model_2_map_nv <- ggplot() 
model_2_map_nv <- model_2_map_nv +  geom_polygon(data = crimeNV_model_2_sigma, aes(x=long, y=lat, group=group, fill=sigma), color = "black", size=0.2) 
model_2_map_nv <- model_2_map_nv + coord_map() 
model_2_map_nv <- model_2_map_nv + labs(x="", y="", title=paste("Non-Violent Crime Differential Growth"), fill="Trend over Time", caption="Model 2")
model_2_map_nv <- model_2_map_nv + cleanup + scale_fill_gradient(low = "blue", high = "orange")

grid.arrange(model_2_map_v, model_2_map_nv, ncol=2)
```

##### Model 3

Finally, the third model predicts the count of crime incidents in an area given its demographics, year, and income level. It also takes into account the interaction between income and race.

Tested the predictive model by predicting crime counts in 2016 and comparing it to the actual crime counts in 2016.


- Refer to Simpson's paradox to justify interaction term.

- Discuss the parameter results

- Add map

```{r, echo=FALSE, include=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
train_data <- Model_Data %>%
  filter(Year != 2016)

data = list(ns=nrow(train_data), y=train_data$total, n=train_data$total_population, income=train_data$income, white=train_data$percent_white, time=train_data$time)
head(train_data)
```

```{r, echo=FALSE, include=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
#Specify the model
crime_model_3 <- "model{
    #Data
    for(i in 1:ns) {
      y[i] ~ dbin(p[i], n[i])
      logit(p[i]) = beta[1] + beta[2]*time[i] + beta[3]*income[i] + beta[4]*white[i] + beta[5]*white[i]*income[i]
    }
    
    #Priors
    for(i in 1:5){
      beta[i] ~ dnorm(0, tau[i])
      tau[i] ~ dgamma(0.5, 0.0005)
    }
    
}"

#set up an algorithm to simulate the posterior by 
#combining the model (nba_model) and data (y)
#set the random number seed
crime_jags_3 <- jags.model(textConnection(crime_model_3), data=data,
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))


#simulate a sample from the posterior 
#note that we specify both mu and tau variables
crime_sim_3 <- coda.samples(crime_jags_3, variable.names=c("beta","tau"), n.iter=60000)

#store the samples in a data frame:    
crime_data_3 <- data.frame(crime_sim_3[[1]])
```

```{r, echo=FALSE, include=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
crime_data_3 <- crime_data_3[20000:nrow(crime_data_3), ]
crime_data_3_sum <- as.data.frame(colMeans(crime_data_3))

test_data <- Model_Data %>%
  filter(Year == 2016)

model_3_predictor <- function(param, income, percent_nonwhite, year, population){
   c <- (param[1,1] + param[2,1] * year + param[3,1] * income + param[4,1] * percent_nonwhite + param[5,1] * percent_nonwhite * income)
   p <- exp(c)/(1 + exp(c))
   return(p * population)
}

predicted_crime_count <- model_3_predictor(crime_data_3_sum, test_data$income, test_data$percent_white, test_data$time, test_data$total_population)

actual_crime_count <- test_data$total 
crime_count_diff <- predicted_crime_count - actual_crime_count

zip <- readOGR(dsn="Boundaries - ZIP Codes", layer="geo_export_e1262361-5c82-45ee-8427-ef228e06dc4a")
zip_df <- fortify(zip, region = "zip")
crime_model_3_count_diff <- left_join(zip_df, data.frame(id=as.character(unique(test_data$zip)), crime_difference=crime_count_diff), by='id')
head(crime_model_3_count_diff)
```

```{r, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
model_3_map <- ggplot() 
model_3_map <- model_3_map +  geom_polygon(data = crime_model_3_count_diff, aes(x=long, y=lat, group=group, fill=crime_difference), color = "black", size=0.2) 
model_3_map <- model_3_map + coord_map() 
model_3_map <- model_3_map + labs(x="", y="", title=paste("Difference in Crime Count by Zipcode"), caption="Model 3", fill="Count Difference")
model_3_map <- model_3_map + cleanup + scale_fill_gradient(low = "blue", high = "orange")
print(model_3_map)
```

- Discuss interpretation of map


### Next Steps

**Discuss future work that could be done on your project. What are the limitations of your current data/models/algorithms?**

In the future, we are interested in examining hotspots for specific types of crime in Chicago.

### Bibliography

Braga, Anthony A., Andrew V. Papachristos, and David M. Hureau. 2012. “The Effects of Hot Spots Policing on Crime: An Updated Systematic Review and Meta-Analysis.” Justice Quarterly iFirst:1–31.

Law, Jane, et al. “Analyzing Hotspots of Crime Using a Bayesian Spatiotemporal Modeling Approach: A Case Study of Violent Crime in the Greater Toronto Area.” Geographical Analysis, vol. 47, no. 1, Oct. 2014, pp. 1–19.

https://www.theatlantic.com/politics/archive/2017/01/chicago-homicide-spike-2016/514331/

https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2/data


Hierarchial Bayesian Spatial Models for Alcohol Availability, drug "hot spots"

### Appendix and supplementary material