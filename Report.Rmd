---
title: "Examining Crime Hotspots in Chicago Using Bayesian Statistics"
author: "Jina Park, Phuc Nguyen"
date: "12/7/2017"
output: html_document
---

### Motivation

Chicago currently leads the United States with the greatest number of homicides and violent crimes. In 2016, the number of homicides in Chicago increased 58% from the year before (Ford, 2017). Using police data from the City of Chicago's Data Portal, we examine crime hot spots in Chicago and whether crime rates differ by geographic and demographic information. In this report, we define hot spots as areas with greater increases, or smaller decreases, in crime rates over time relative to other locations. In addition, we examine hot spots for both violent and non-violent crimes. Understanding crime hot spots proves advantageous to law enforcement as they can better understand crime trends and create crime management strategies accordingly (Law, et al. 2014).  

##### Literature Review 

Law, et al. (2014) identifies hot spots and overall trends of violent crime in the Greater Toronto Area using a Bayesian spatiotemporal modeling approach. Although frequentists define hot spots as areas with high crime rates that are also surrounded by other high-crime areas for one time period, Bayesian statistics allow us to examine how hot spots change over time (Law, et al. 2014). In particular, the Bayesian approach allows us to predict hot spots at various zipcode levels and crime rates over time. For this reason, we apply similar Bayesian methods to examine how hot spots in Chicago change year over year. 

### Methods and Results

Although Chicago is widely known for its high level of violent crime, certain areas of Chicago are prone to more crime than others. In Figure 1 below, the concentration of crime in Chicago is particularly high in areas highlighted in red. The concentration of crime appears to shift slightly from 2010 to 2016, with greater crime rates in northeast Chicago in 2016 compared to 2010.  In our analysis, we define hot spots as areas with high concentrations of crime that increases above average over time. For this reason, the areas that turn more red over time can be identified as hot spots. 


```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# Load Library
library(tidyr)
library(rjags)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(MacBayes)
library(choroplethrZip)
library(rgdal)
library(devtools)
library(choroplethr)
library(choroplethrMaps)
library(mapproj)
library(grid)
library(gridExtra)

#install.packages("devtools")
#install_github('arilamstein/choroplethrZip@v1.5.0')
```

```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# Load data
Crime <- read.csv('Crime_sample_2010_to_2017.csv')
Model_Data <- read.csv("Crime_models_data.csv")
Model_Data_Violent <- read.csv("Crime_models_violent_data.csv")
Model_Data_Nviolent <- read.csv("Crime_models_nonviolent_data.csv")

train_data <- Model_Data %>% filter(Year < 2016)
test_data <- Model_Data %>% filter(Year==2016)

load("model_1_MCMC_samples_train.Rda")
load("model_2_MCMC_samples_train.Rda")
load("model_3_MCMC_samples_train.Rda")
load("model_1_MCMC_samples_non-violent.Rda")
load("model_1_MCMC_samples_violent.Rda")
load("model_2_MCMC_samples_non-violent.Rda")
load("model_2_MCMC_samples_violent.Rda")
load("model_3_MCMC_samples_non-violent.Rda")
load("model_3_MCMC_samples_violent.Rda")
```

```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# Map cleanup: remove grey background grids in maps visualizations
cleanup <- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = 'white', colour = 'white'),
        axis.line = element_line(colour = "white"),
        axis.ticks=element_blank(), axis.text.x=element_blank(),
        axis.text.y=element_blank())
```

```{r, include=FALSE, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE}
#load the shape file to make maps
zip <- readOGR(dsn="Boundaries - ZIP Codes", layer="geo_export_e1262361-5c82-45ee-8427-ef228e06dc4a")
```

```{r, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE, fig.width=15, fig.height=6, fig.align="center"}
# Make density map of crime incidents in year 2010, 2013, 2016 to see if there is time trend
Crime_2010 <- Crime %>% filter(Year == 2010)
gg2010 <- ggplot()
gg2010 <- gg2010 + geom_polygon(data=zip, aes(x=long, y=lat, group=group), colour="black", fill="grey90", size=0.5) 
gg2010 <- gg2010 + stat_density2d(data=Crime_2010, show.legend=F, aes(x=Longitude, y=Latitude, fill=..level.., alpha=..level..), geom="polygon", size=2, bins=10)
gg2010 <- gg2010 + scale_fill_gradient(low="deepskyblue2", high="firebrick1", name="Distribution")
gg2010 <- gg2010 +  coord_map("polyconic")
gg2010 <- gg2010 + labs(x=NULL, y=NULL,
                  subtitle=NULL,
                  caption="2010")
gg2010 <- gg2010 + cleanup + theme(plot.margin = unit(c(0,0,0,0), "lines"))

Crime_2013 <- Crime %>% filter(Year == 2013)
gg2013 <- ggplot()
gg2013 <- gg2013 + geom_polygon(data=zip, aes(x=long, y=lat, group=group), colour="black", fill="grey90", size=0.5) 
gg2013 <- gg2013 + stat_density2d(data=Crime_2013, show.legend=F, aes(x=Longitude, y=Latitude, fill=..level.., alpha=..level..), geom="polygon", size=2, bins=10)
gg2013 <- gg2013 + scale_fill_gradient(low="deepskyblue2", high="firebrick1", name="Distribution")
gg2013 <- gg2013 +  coord_map("polyconic")
gg2013 <- gg2013 + labs(x=NULL, y=NULL,
                  subtitle=NULL,
                  caption="2013")
gg2013 <- gg2013 + cleanup + theme(plot.margin = unit(c(0,0,0,0), "lines"))


Crime_2016 <- Crime %>% filter(Year == 2016)
gg2016 <- ggplot()
gg2016 <- gg2016 + geom_polygon(data=zip, aes(x=long, y=lat, group=group), colour="black", fill="grey90", size=0.5) 
gg2016 <- gg2016 + stat_density2d(data=Crime_2016, show.legend=F, aes(x=Longitude, y=Latitude, fill=..level.., alpha=..level..), geom="polygon", size=2, bins=10)
gg2016 <- gg2016 + scale_fill_gradient(low="deepskyblue2", high="firebrick1", name="Distribution")
gg2016 <- gg2016 +  coord_map("polyconic")
gg2016 <- gg2016 + labs(x=NULL, y=NULL,
                  subtitle=NULL,
                  caption="2016")
gg2016 <- gg2016 + cleanup + theme(plot.margin = unit(c(0,0,0,0), "lines"))

grid.arrange(gg2010, gg2013, gg2016, ncol=3, heights=15, top=textGrob("Figure 1: Concentration of Crime in Chicago", gp=gpar(fontsize=20, fontface="bold")))
```

```{r, include=FALSE, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE}
# Visualizations of demographics data in 2010
data(df_pop_zip)
data(df_zip_demographics)

zip_percent_white <- df_zip_demographics[c("region", "percent_white")]
colnames(zip_percent_white)[2] <- "value"

zip_percent_black <- df_zip_demographics[c("region", "percent_black")]
colnames(zip_percent_black)[2] <- "value"

zip_percent_asian <- df_zip_demographics[c("region", "percent_asian")]
colnames(zip_percent_asian)[2] <- "value"

zip_percent_hispanic <- df_zip_demographics[c("region", "percent_hispanic")]
colnames(zip_percent_hispanic)[2] <- "value"

zip_per_capita_income <- df_zip_demographics[c("region", "per_capita_income")]
colnames(zip_per_capita_income)[2] <- "value"

zip_median_rent <- df_zip_demographics[c("region", "median_rent")]
colnames(zip_median_rent)[2] <- "value"

zip_median_age <- df_zip_demographics[c("region", "median_age")]
colnames(zip_median_age)[2] <- "value"

data(zip.regions)
chi_nap_elg <- subset(zip.regions, zip.regions$cbsa.title=="Chicago-Naperville-Elgin, IL-IN-WI")
cook_county <- subset(chi_nap_elg, chi_nap_elg$county.name == "cook")
cook_fips <- cook_county$county.fips.numeric
```


Figure 2, shown below, highlights the significant demographic differences across the zipcodes in Chicago. While per capita income and median rent appear positively correlated with both the Asian and White populations in Chicago, it appears negatively correlated with the Hispanic and Black populations. Since crime rates might differ across different ethnic and income groups, we take these demographics into consideration when predicting hot spots in Chicago.


```{r, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE, fig.width=15, fig.height=15, fig.align="center"}
pop_map <- zip_choropleth(df_pop_zip, 
               county_zoom = cook_fips, 
               title="Total Population") + coord_map()

white_pop_map <- zip_choropleth(zip_percent_white, 
               county_zoom = cook_fips, 
               title="White Population") + coord_map()

black_pop_map <- zip_choropleth(zip_percent_black, 
               county_zoom = cook_fips, 
               title="Black Population") + coord_map()

asian_pop_map <- zip_choropleth(zip_percent_asian, 
               county_zoom = cook_fips, 
               title="Asian Population") + coord_map()

hisp_pop_map <- zip_choropleth(zip_percent_hispanic, 
               county_zoom = cook_fips, 
               title="Hispanic Population") + coord_map()

income_map <- zip_choropleth(zip_per_capita_income, 
               county_zoom = cook_fips, 
               title="Per Capita Income") + coord_map()

rent_map <- zip_choropleth(zip_median_rent, 
               county_zoom = cook_fips, 
               title="Median Rent") + coord_map()

age_map <- zip_choropleth(zip_median_age, 
               county_zoom = cook_fips, 
               title="Median Age") + coord_map()

grid.arrange(pop_map, white_pop_map, black_pop_map, asian_pop_map, hisp_pop_map, income_map, rent_map, age_map, ncol=3, top=textGrob("Figure 2: Demographic Maps of Chicago by Zipcode", gp=gpar(fontsize=20, fontface="bold")))
```

##### Data and Methodology

To complete our analyses, we utilized data from the City of Chicago's Data Portal. We filtered for crimes that occurred between 2010-2017, in which each row represents a crime observation in Chicago. We standardized the values for year and income to ease the interpretability of our models and help the Markov Chains converge. We then focused on the following variables for our analysis: time, type of crime, and location. In addition to our crime data, we used the 2010 Census data for the percentage of white and nonwhite populations, per capita income, and total population for each zipcode in Chicago.

To derive our models, we used the Gibbs sampler. We then checked for convergence of our Markov Chains by using using effective sample sizes and a combination of visual indicators, such as running mean plots, trace plots of our parameters, and a Gelman-Rubin diagnostic statistics. These tools can be accessed using the *running_mean_plot* function in the MacBayes package and *gelman.diag* and *effectiveSize* functions in the package, coda. Upon checking the diagnostics for convergence, we observed autocorrelation between our parameters and reparametrized our models by centering the mean and orthogonalizing correlated predictors. We ran all of our models for 30,000 iterations for stabilization and discarded the first 5,000 iterations to calculate the posterior means. Finally, we checked all of the posterior means for statistical significance at the 5% level.

##### Overview of Models

Figure 3 plots the relationship between the log of the crime rate and year for zipcodes in Chicago. It shows a slight downward trend in the log of crime rates as the years increase. Since it is plausible that overall crime rates have a negative, linear trend over time, we incorporate a time trend in our models. Although Figure 3 displays a lot of noise, we believe it is also reasonable for each zipcode to have a different slope and intercept.

```{r, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE,fig.width=15, fig.height=8, fig.align="center"}
Crime_count <- Model_Data %>%
  select(Year, zip, total) %>%
  spread(key=Year, value=total)
rownames(Crime_count) <- Crime_count$zip 
Crime_count <- Crime_count %>% select(-zip)
Crime_count[is.na(Crime_count)] <- 0

Population <- Model_Data %>%
  select(total_population, zip, Year) %>%
  spread(key=Year, value=total_population) %>%
  select('2010', zip)
rownames(Population) <- Population$zip
Population <- Population %>% select(-zip)
Population[is.na(Population)] <- 0
Population.vector <- Population$`2010`

Crime_count_log_calc <- log(Crime_count/Population.vector)
Crime_count_log <- Crime_count_log_calc %>%
  rownames_to_column() %>%
  gather(key=year, value=crime_count_log, -rowname) %>%
  mutate(zip=rowname) %>%
  select(zip, year, crime_count_log) %>%
  mutate(year=as.numeric(year))

ggplot(Crime_count_log, aes(x=year, y=crime_count_log, colour=zip)) + geom_point() + geom_line() + labs(title="Figure 3: Crime Rate Over Time", y="Log of Crime Rate", x="Year", color="Zipcodes")
```


##### Model 1

In our first model, we predict crime hot spots in Chicago using a simple model that incorporates a time trend. In this model, $y_{ij}$ is the observed crime count in zipcode $i$ and year $j$ and is modeled with a Binomial distribution. The parameters are $p_{ij}$, which is the inherent crime rate, and $n_{ij}$, which is the total population in zipcode $i$ and year $j$. We model $y_{ij}$ with a Binomial distribution because a Binomial distribution is typically used to model the count of an event given a probability between 0 and 1. For our analysis, we assume that population and other demographic information of each zipcode remain unchanged from the 2010 Census. 

$$y_{ij} \mid p_{ij}, \beta_0,\beta_{i}, \delta_0,\delta_{i}, \tau_0, \tau_1 \sim Bin(p_{ij}, n_{ij})$$ 

$$log(\frac{p_{ij}}{1-p_{ij}}) \mid \beta_0, \beta_{i}, \delta_0,\delta_{i}, \tau_0, \tau_1 = \beta_{i} + \delta_{i}* time_{j}$$
$$\beta_{i} \mid \beta_0, \tau_0 \sim N(\beta_0, \tau_{0}^{-1})$$
$$\delta_{i} \mid \delta_0, \tau_1 \sim N(\delta_0, \tau_{1}^{-1})$$
$$\beta_0 \sim N(0, 1000^2)$$
$$\delta_0 \sim N(0, 1000^2)$$
$$\tau_{0}, \tau_{1} \sim Gamma(0.5, 0.0005)$$
where $i=\{1,...,58\}$, $j=\{1,...,5\}$

As shown in Figure 3, it appears reasonable to model the log of the crime rate as a linear function of time. We therefore set the log odds of the inherent crime rate in zipcode $i$ and year $j$, $log(\frac{p_{ij}}{1-p_{ij}})$, as a linear function of time where $\beta_{i}$ and $\delta_{i}$ represent a different intercept and time trend for each zipcode $i$, respectively. This indicates that we assume each zipcode has a different change in crime rate over time.

The prior distributions of $\beta_{i}$ are normally distributed with a mean of $\beta_0$, the grand intercept, and a precision of $\tau_0$. Similarly, the prior distributions of $\delta_i$ are normally distributed with a mean of $\delta_0$, the grand time trend, and precision $\tau_1$. The precisions, $\tau_{0}$ and $\tau_{1}$, are modeled with a Gamma distribution where the mean equals 0.00025. This is equivalent to a mean standard deviation of 63 for $\beta_{i}$ and $\delta_{i}$'s normal distributions. A large variance indicates that $\tau$ is a vague prior given that the grand mean of $\beta_{i}$ and $\delta_{i}$ are approximately -7.49 and -0.066, respectively. A grand mean of the time trend of -0.066 signifies that the average change in the crime rate over time is roughly -0.066. The standard deviation of the change in the crime rate over time is 0.023. The priors for $\beta_{0}$ and  $\delta_{0}$ are also vague with a mean of 0 and standard deviation of 1,000. Based on the 95% confidence intervals of our parameters, we conclude that all of the intercepts and the vast majority of our parameters in Model 1 are significant at the 5% level. 


```{r, include=FALSE, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE,fig.align="center"}

#Create a data frame containing posterior means for each zipcode
n = length(unique(train_data$zip))
crime_model_1_mean <- matrix(nrow=n, ncol=1) #find posterior means of delta_i
for (i in 1:n) {
      crime_model_1_mean[i, ] <- mean(crime_data_1[[i+59]])
}
zip_df <- fortify(zip, region = "zip")
crime_model_1_delta <- left_join(zip_df, data.frame(id=as.character(unique(train_data$zip)), delta=crime_model_1_mean), by='id')
```

```{r, message=FALSE, warning=FALSE, cache=TRUE, echo=FALSE, fig.width=15, fig.height=8, fig.align="center"}
#Make a map
model_1_map <- ggplot() 
model_1_map <- model_1_map +  geom_polygon(data = crime_model_1_delta, aes(x=long, y=lat, group=group, fill=delta), color = "black", size=0.2) 
model_1_map <- model_1_map + coord_map() 
model_1_map <- model_1_map + labs(x="", y="", title=paste("Figure 4: Crime Differential Growth by Zipcode"), caption="Model 1", fill="Trend over Time")
model_1_map <- model_1_map + cleanup + scale_fill_gradient(low = "blue", high = "orange")
print(model_1_map)
```

Using Model 1, Figure 4 maps the time trend, $\delta_{i}$ and shows the crime differential growth for each zipcode in Chicago. The map indicates that overall crime rates are decreasing in all areas of Chicago over time. The crime hot spots are shown in areas highlighted in bright orange where crime is not decreasing as much over time compared to other areas, particularly areas colored in dark blue and purple.

Since Chicago is particularly well-known for its high level of violent crime including homicides, we divided our data into two groups for violent and non-violent crimes to examine whether hot spots for these two groups vary. We classified the following types of crime as 'violent': robbery, battery, burglary, assault, homicide, sex offense, criminal sexual assault, and arson. All other crime types in our data are considered 'non-violent'.


```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE, comment=NA}
#Making a dataframe for visualization of map

n1 = length(unique(Model_Data_Violent$zip))
n2 = length(unique(Model_Data_Nviolent$zip))
crimeV_model_1_mean <- matrix(nrow=n1, ncol=1)
for (i in 1:n) {
      crimeV_model_1_mean[i, ] <- mean(crimeV_data_1[[i+59]])
}
crimeNV_model_1_mean <- matrix(nrow=n2, ncol=1)
for (i in 1:n) {
      crimeNV_model_1_mean[i, ] <- mean(crimeNV_data_1[[i+59]])
}

crimeV_model_1_delta <- left_join(zip_df, data.frame(id=as.character(unique(Model_Data_Violent$zip)), delta=crimeV_model_1_mean), by='id')

crimeNV_model_1_delta <- left_join(zip_df, data.frame(id=as.character(unique(Model_Data_Nviolent$zip)), delta=crimeNV_model_1_mean), by='id')
```

```{r, message=FALSE, warning=FALSE, echo=FALSE, comment=NA, fig.width=15, fig.height=15, fig.align="center"}
model_1_map_v <- ggplot() 
model_1_map_v <- model_1_map_v +  geom_polygon(data = crimeV_model_1_delta, aes(x=long, y=lat, group=group, fill=delta), color = "black", size=0.2) 
model_1_map_v <- model_1_map_v + coord_map() 
model_1_map_v <- model_1_map_v + labs(x="", y="", title=paste("Violent Crime"), fill="Trend over Time", caption="Model 1")
model_1_map_v <- model_1_map_v + cleanup + scale_fill_gradient(low = "blue", high = "orange", limits=c(-0.1, -0.01))
```

```{r, message=FALSE, warning=FALSE, echo=FALSE, comment=NA, fig.width=15, fig.height=8, fig.align="center"}
model_1_map_nv <- ggplot() 
model_1_map_nv <- model_1_map_nv +  geom_polygon(data = crimeNV_model_1_delta, aes(x=long, y=lat, group=group, fill=delta), color = "black", size=0.2) 
model_1_map_nv <- model_1_map_nv + coord_map() 
model_1_map_nv <- model_1_map_nv + labs(x="", y="", title=paste("Non-Violent Crime"), fill="Trend over Time", caption="Model 1")
model_1_map_nv <- model_1_map_nv + cleanup + scale_fill_gradient(low = "blue", high = "orange", limits=c(-0.1, -0.01))

grid.arrange(model_1_map_v, model_1_map_nv, ncol=2, top=textGrob("Figure 5: Crime Differential Growth by Zipcode and Type of Crime", gp=gpar(fontsize=20, fontface="bold")))
```

Figure 5 above indicates that both violent and non-violent crimes in Chicago are decreasing over time. However, non-violent crimes in Chicago appear to decrease over time by a greater extent than violent crimes. This is indicated by a darker shade of purple for non-violent crimes. 

##### Model 2

In Figure 6, we plotted the log of per capita income against the log of crime rate by non-white percentage in each zipcode. In areas with large white populations, an increase in the per capita income results in greater crime rates. However, when an area has a greater non-white population, the crime rate seems to fall as per capita income increases. Figure 6 thus seems to suggest that the relationship between income and crime varies depending on an area's demographic population. For this reason, we derived Model 2 by taking into consideration income and the percentage of white people in each area.

```{r, include=FALSE, message=FALSE, warning=FALSE, echo=FALSE, comment=NA}
Crime_count_log <- Model_Data %>%
  mutate(log_rate = log(total/total_population)) %>%
  select(zip, Year, log_rate)

Model_Data_1 <- Model_Data %>%
  filter(Year == 2010) %>%
  mutate(percent_nonwhite = 100 - percent_white) %>%
  select(zip, per_capita_income, percent_nonwhite) %>%
  right_join(Crime_count_log, by="zip") 
```

```{r, message=FALSE, warning=FALSE, echo=FALSE, comment=NA, fig.width=15, fig.height=8, fig.align="center"}
ggplot(Model_Data_1, aes(x=log(per_capita_income), y=log_rate, colour=percent_nonwhite)) + geom_point() + labs(x="Log of Per Capita Income", y="Log of Crime Rate", title="Figure 6: Relationship between Per Capita Income and Crime Rate", color="Nonwhite Percentage") 
```

In our second model, we examine changes in the crime rate while taking into account differences in race and income levels in specific areas. Model 2 resembles Model 1, except it takes into consideration income and demographic information for each zipcode. As shown in Figure 6, the relationship between income and crime rate seems to be different for areas with varying levels of white populations. Therefore, we decided to discretize our demographic variable into five groups depending on the percentage of white people living in each zipcode: more than 80%, between 60-80%, between 40-60%, between 20-40%, and less than 20% white perentage.

$$y_{ij} \mid p_{ij}, \beta_0,\beta_{i}, \delta_0,\delta_{i}, \sigma_e, \tau_0, \tau_1, \tau_2 \sim Bin(p_{ij}, n_{ij})$$
$$log(\frac{p_{ij}}{1-p_{ij}}) \mid \beta_0,\beta_{i}, \delta_0,\delta_{i}, \sigma_e, \tau_0, \tau_1, \tau_2 = \beta_{i} + \delta_{i} * time_{j}$$

$$\beta_{i} \mid \beta_0, \sigma_e, \tau_0, \tau_2 \sim N( \beta_0 + \sum_{e=1}^{5} \sigma_{e} * income_{i} * perwhite_{e}, \tau_{0})$$
$$\delta_{i} \mid \delta_0, \tau_1 \sim N(\delta_0, \tau_{1})$$
$$\beta_0 \sim N(0, 1000^2)$$
$$\delta_0 \sim N(0, 1000^2)$$

$$\sigma_{e} \mid \tau_2 \sim N(0, \tau_{2})$$
$$\tau_{0}, \tau_{1}, \tau_{2} \sim Gamma(0.5, 0.0005)$$
where $i=\{1,...,58\}$, $j=\{1,...,5\}$, $e=\{1, ..., 5\}$


The variable, $perwhite_{e}$, is a categorical variable that classifies each zipcode based on its demographics. The parameter, $\sigma_{e}$, allows each group to have a different relationship with the log odds of the crime rate as income increases. In addition, we provide vague priors for all the parameters, similar to Model 1, due to limited prior knowledge. Based on the 95% confidence intervals of our parameters, we conclude that all of the intercepts and the vast majority of our parameters in Model 2 are significant. This means that there is a significant relationship between crime rate and income in these areas. That said, all other race groups are not considered significant at the 5% level. 

```{r, include=FALSE, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE}
posterior_means <- crime_data_2 %>% colMeans()
start_index = which(names(posterior_means) %in% c("sigma.1."))
crime_model_2_sigma <- Model_Data
crime_model_2_sigma$sigma <- recode(crime_model_2_sigma$racegr, `1`=posterior_means[start_index],
                                   `2`=posterior_means[start_index+1],
                                   `3`=posterior_means[start_index+2],
                                   `4`=posterior_means[start_index+3],
                                   `5`=posterior_means[start_index+4])
crime_model_2_sigma <- crime_model_2_sigma %>%
  mutate(id = as.character(zip)) %>%
  right_join(zip_df, by="id")
```

Figure 7 maps $\sigma_{e}$, which represents the relationship between crime rate and income. The area highlighted in blue represents areas with less than 20% white populations. In these areas, the number of crime decreases over time as per capita income increases. The bright orange areas represent areas with between 60-80% white populations. In these areas, crime increases over time as per capita income increases. This map follows closely to Figure 6, which indicates a negative relationship between crime rate and per capita income in areas with large non-white populations.

```{r, cache=TRUE, message=FALSE, warning=FALSE, echo=FALSE, fig.width=15, fig.height=8, fig.align="center"}
model_2_map <- ggplot() 
model_2_map <- model_2_map +  geom_polygon(data = crime_model_2_sigma, aes(x=long, y=lat, group=group, fill=sigma), color = "black", size=0.2) 
model_2_map <- model_2_map + coord_map() 
model_2_map <- model_2_map + labs(x="", y="", title=paste("Figure 7: Crime Differential Growth Based on Income and Demographics"), caption="Model 2", fill="Trend over Income")
model_2_map <- model_2_map + cleanup + scale_fill_gradient(low = "blue", high = "orange") + theme(plot.title = element_text(size=18))
print(model_2_map)
```

Figure 8 examines the crime differential growth based on income and demographics for both violent and non-violent crimes. According to the maps, the number of violent crime increases over time as per capita income increases for areas with between 60-80% white populations, as indicated in orange. In areas where the white population falls below 20%, the number of violent crimes decreases as per capita income increases, as highlighted in blue. This indicates that areas with large non-white populations face lower violent crimes as income increases wheras areas with larger white populations face the opposite effect with more income. The trend for non-violent crimes is similar to the trend in violent crimes. However, in areas with less than 20% white populations, crime rates are not decreasing as much as violent crimes when income increases. In addition, in areas with between 60-80% white populations, non-violent crime is increasing to a greater extent than violent crime as income increases.

In regions with between 60-80% white populations, the posterior mean for $\sigma$ equals 0.365 (std. error = 6.1e-04) for violent crimes and 0.738 (std. error = 7.03e-03) for non-violent crimes. In regions with less than 20% white population, this posterior mean equals -1.192 (std. error = 1.22e-03) for violent crimes and -0.687 (std. error = 1.539e-03) for non-violent crimes. As mentioned above, these two regions are the only groups with statistically significant parameters.


```{r, echo=FALSE, include=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
posterior_means <- crimeV_data_2 %>% colMeans()
crimeV_model_2_sigma <- Model_Data_Violent
crimeV_model_2_sigma$sigma <- recode(crimeV_model_2_sigma$racegr, `1`=posterior_means[start_index],
                                   `2`=posterior_means[start_index+1],
                                   `3`=posterior_means[start_index+2],
                                   `4`=posterior_means[start_index+3],
                                   `5`=posterior_means[start_index+4])
crimeV_model_2_sigma <- crimeV_model_2_sigma %>%
  mutate(id = as.character(zip)) %>%
  right_join(zip_df, by="id")

posterior_means <- crimeNV_data_2 %>% colMeans()
crimeNV_model_2_sigma <- Model_Data_Nviolent
crimeNV_model_2_sigma$sigma <- recode(crimeNV_model_2_sigma$racegr, `1`=posterior_means[start_index],
                                   `2`=posterior_means[start_index+1],
                                   `3`=posterior_means[start_index+2],
                                   `4`=posterior_means[start_index+3],
                                   `5`=posterior_means[start_index+4])
crimeNV_model_2_sigma <- crimeNV_model_2_sigma %>%
  mutate(id = as.character(zip)) %>%
  right_join(zip_df, by="id")
```

```{r, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
model_2_map_v <- ggplot() 
model_2_map_v <- model_2_map_v +  geom_polygon(data = crimeV_model_2_sigma, aes(x=long, y=lat, group=group, fill=sigma), color = "black", size=0.2) 
model_2_map_v <- model_2_map_v + coord_map() 
model_2_map_v <- model_2_map_v + labs(x="", y="", title=paste("Violent Crime"), fill="Trend over Income", caption="Model 2")
model_2_map_v <- model_2_map_v + cleanup + scale_fill_gradient(low = "blue", high = "orange", limits=c(-1.2,0.8))
```

```{r, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE, fig.width=15, fig.height=8, fig.align="center"}
model_2_map_nv <- ggplot() 
model_2_map_nv <- model_2_map_nv +  geom_polygon(data = crimeNV_model_2_sigma, aes(x=long, y=lat, group=group, fill=sigma), color = "black", size=0.2) 
model_2_map_nv <- model_2_map_nv + coord_map() 
model_2_map_nv <- model_2_map_nv + labs(x="", y="", title=paste("Non-violent Crime"), fill="Trend over Income", caption="Model 2")
model_2_map_nv <- model_2_map_nv + cleanup + scale_fill_gradient(low = "blue", high = "orange", limits=c(-1.2,0.8))

grid.arrange(model_2_map_v, model_2_map_nv, ncol=2, top=textGrob("Figure 8: Crime Differential Growth Based on Income, Demographics, and Type of Crime", gp=gpar(fontsize=20, fontface="bold")))
```


##### Model 3

Finally, our last model, Model 3, predicts the count of crime incidents in an area given its demographics, year, and income levels. Similar to Model 2, it takes into account the interaction between income and race. However, instead of discretizing the demographic variable (i.e. percent white), we keep the variable as continuous. In addition, we model the crime rate with an interaction term between income and the percentage of white populations. 

Since the correlation between income and the percentage of white population is high, with a correlation of 0.72, we correct for the collinearity between the two predictors. We orthogonalize the predictors by creating a new predictor, $perwhite^{+}$. This predictor represents the portion of the original predictor that cannot be explained by the $income$ variable. Similarly, the $(perwhite*income)^{+}$ variable represents the portion of the interaction term that is not already explained by the $income$ and $perwhite$ variables. In addition, all priors for our parameters are vague, similar to both Models 1 and 2.

$$y_{ij} \mid p_{ij}, \beta_0, \beta_{i}, \delta_0, \delta_{i}, \sigma_1, \sigma_2, \sigma_3, \tau_0, \tau_1 \sim Bin(p_{ij}, n_{ij})$$
$$log(\frac{p_{ij}}{1-p_{ij}}) \mid \beta_0, \beta_{i}, \delta_0, \delta_{i}, \sigma_1, \sigma_2, \sigma_3, \tau_0, \tau_1 = \beta_{i} + \delta_{i} * time_{j}$$
$$\beta_i \mid \beta_0, \sigma_1, \sigma_2, \sigma_3, \tau_0 \sim N(\beta_0 + \sigma_1*income_i + \sigma_2*perwhite^{+}_i + \sigma_3*(perwhite*income)^{+}_i, \tau_0^{-1})$$


$$\delta_i \mid \delta_{i}, \tau_1 \sim N(\delta_0, \tau_1^{-1})$$
$$\sigma_1, \sigma_2, \sigma_3 \sim N(0, 1000^2)$$
$$\beta_0, \delta_0 \sim N(0, 1000^2)$$
$$\tau_0, \tau_1 \sim Gamma(0.5, 0.0005)$$
where $i=\{1,...,58\}, j=\{1,...,5\}$


Based on the 95% confidence intervals of our parameters, we conclude that all of the intercepts and the majority of our parameters in Model 3 are significant at the 5% level. The mean estimate of $\sigma_{1}$ is -1.94 and the standard error is 0.003. Since $\sigma_{1}$ is considered significant at the 5% level, we conclude that income and crime have a significant and negative relationship. The mean estimate of $\sigma_{2}$ is 7.758 and the standard error is 0.013. Since it is considered significant at the 5% level, crime and the percentage of white population in an area are positively correlated. $\sigma_{3}$ is not considered significant at the 5% level. This suggests that different percentages of white people in an area have no effect on the relationship between crime rate and income. In other words, the interaction term is not significant in this model.

```{r, echo=FALSE, include=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
crime_data_3 <- crime_data_3[20000:nrow(crime_data_3), ]
crime_data_3_sum <- as.data.frame(colMeans(crime_data_3))

model_3_predictor <- function(param, income, percent_nonwhite, year, population){
   c <- (param[1,1] + param[2,1] * year + param[3,1] * income + param[4,1] * percent_nonwhite + param[5,1] * percent_nonwhite * income)
   p <- exp(c)/(1 + exp(c))
   return(p * population)
}

predicted_crime_count <- model_3_predictor(crime_data_3_sum, test_data$income, test_data$percent_white, test_data$time, test_data$total_population)

actual_crime_count <- test_data$total 
crime_count_diff <- predicted_crime_count - actual_crime_count

crime_model_3_count_diff <- left_join(zip_df, data.frame(id=as.character(unique(test_data$zip)), crime_difference=crime_count_diff), by='id')
head(crime_model_3_count_diff)
```

```{r, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE, fig.width=15, fig.height=8, fig.align="center"}
model_3_map <- ggplot() 
model_3_map <- model_3_map +  geom_polygon(data = crime_model_3_count_diff, aes(x=long, y=lat, group=group, fill=crime_difference), color = "black", size=0.2) 
model_3_map <- model_3_map + coord_map() 
model_3_map <- model_3_map + labs(x="", y="", title=paste("Figure 9: Difference in Crime Count by Zipcode"), caption="Model 3", fill="Count Difference")
model_3_map <- model_3_map + cleanup + scale_fill_gradient(low = "blue", high = "orange") + theme(plot.title = element_text(size=18))
print(model_3_map)
```

Figure 9 maps the difference in crime count between the predicted crime count in 2016 and the actual crime count in 2016. In areas highlighted in dark blue and purple, the predicted crime count is much lower than the actual crime count in 2016. In fact, the difference in crime count is negative in all zipcodes. This suggests that crime in 2016 might be greater than the current trend and therefore, our predictions are underestimating the true crime count.

### Conclusion

In general, the crime rate in Chicago has decreased in the periods between 2010 and 2015. In addition, crime rates for both violent and non-violent crimes decreased over time but at varying magnitudes. For areas with lower white populations, crime decreased as income rose. For areas with larger non-white populations, crime rate increased as income increased, indicating a discrepancy in crime rates for different demographic areas. Lastly, our third model suggests that crime in 2016 might be increasing to a greater extent than the current crime trend. To conclude, our hot spots analyses and results might be helpful for law enforcement to better understand crime trends in Chicago and predict future crime rates. As a result, it might help with more efficient crime management in specific areas.

### Next Steps

In the future, we are interested in examining hot spots for specific types of crime in Chicago. For instance, how do hot spots for homicides compare to hot spots for petty theft? To add, we used zipcodes in our analysis due to its familiarity with general audiences. We could potentially repeat the same analysis using tract data since tracts tend to have more consistent boundaries, similar populations, and is the official unit by which the U.S. Census data are collected. In addition, although we have random effects for each zipcode in our analysis, we can also expect to have autocorrelated random effects between zipcodes that are adjacent. This is because adjacent locations tend to have similar crime rates and behaviors. Therefore, adding a random effect term to account for this correlation can help smooth out dramatic differences in crime rates in adjacent locations. Last but not least, we would like to examine crime rates in specific areas of Chicago in more detail. Certain neighborhoods, such as Fuller Park, experience significantly greater homicide rates compared to other areas (Lucido, 2016). It would be interesting to examine what factors contribute to this drastic difference in crime rates such as race, income, graduation rates, and poverty levels. We could also explore specific areas within the neighborhood, such as parks and schools, to find hot spots in more local areas.

### Bibliography

- Braga, Anthony A., Andrew V. Papachristos, and David M. Hureau. 2012. “The Effects of Hot Spots Policing on Crime: An Updated Systematic Review and Meta-Analysis.” Justice Quarterly iFirst:1–31.

- "Crimes - 2001 to Present." City of Chicago Data Portal. Retrieved December 17, 2017.

- Ford, Matt. “What's Causing Chicago's Homicide Spike?” The Atlantic, Atlantic Media Company, 24 Jan. 2017.

- Law, Jane, et al. “Analyzing Hotspots of Crime Using a Bayesian Spatiotemporal Modeling Approach: A Case Study of Violent Crime in the Greater Toronto Area.” Geographical Analysis, vol. 47, no. 1, Oct. 2014, pp. 1–19.

- Lucido, Gary. “Chicago's Safest And Most Dangerous Neighborhoods: Homicide Rates.” ChicagoNow, 28 July 2016.


### Appendix and supplementary material

##### Load Libraries
```{r, eval=FALSE, echo=TRUE, message=FALSE, warning=FALSE, comment=NA}
library(dplyr)
library(lubridate)
library(tidyr)
library(rjags)
library(ggplot2)
library(tidyverse)
library(MacBayes)
library(choroplethrZip)
library(rgdal)
library(devtools)
library(choroplethr)
library(choroplethrMaps)
library(mapproj)
library(grid)
library(gridExtra)

##Install only if not installed before (uncomment)
#install.packages("devtools")
#install_github('arilamstein/choroplethrZip@v1.5.0')
```

#### Clean Data
```{r, eval=FALSE, echo=TRUE, message=FALSE, warning=FALSE, comment=NA}
#Reads in the original dataset downloaded from City of Chicago Data Portal
Crime = read.csv('Crimes_-_2001_to_present.csv')

#Filter for year 2010 to present (2017) and clear some columns. Saved resulting data
Crime = Crime %>%
  filter(Year >= 2010 & !is.na(Latitude)) %>%
  mutate(Arrest = as.numeric(Arrest == 'true'), Domestic = as.numeric(Domestic == 'true'), Date = as.POSIXct(strptime(Date, "%m/%d/%Y %H:%M:%S %p")))
head(Crime)
write.csv(Crime, file="Crime_2010_to_2017.csv")

#Take a random sample to work with
Crime = read.csv('Crime_2010_to_2017.csv')
Crime_sample = Crime[sample(1:nrow(Crime), 10000,
                             replace=FALSE),]
Crime_sample = Crime_sample %>% filter(!is.na(Latitude))
write.csv(Crime_sample, file='Crime_sample_2010_to_2017.csv')


#Format data after loading it in RStudio everytime if planning to work with Date variable
Crime_sample = Crime_sample %>%
  mutate(Date = as.POSIXct(strptime(Date, "%Y-%m-%d %H:%M:%S")))
```

#### Create Model Data
```{r, eval=FALSE, echo=TRUE, message=FALSE, warning=FALSE, comment=NA}
#### Project observations to ZIP codes boundaries

#load sample of crime incident data that have been cleaned using codes in clean_data.R

Crime = read.csv('Crime_sample_2010_to_2017.csv')

#load shapefile
zip_shp <- readOGR(dsn="Boundaries - ZIP Codes", layer="geo_export_e1262361-5c82-45ee-8427-ef228e06dc4a")
temp <- zip_shp
zip_df <- fortify(temp, region = "zip") #turn shapefile into dataframe

#needs to reassign CRS for shapefile
new_CRS <- CRS("+init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
zip_shp <- sp::spTransform(zip_shp, new_CRS)

#summarize number of crime count per year per zipcode
years <- unique(Crime$Year)
Hotspot_Crime <- data.frame()

for(i in 1:length(years)){
  year <- years[i]
  Current_Year <- Crime %>% filter(Year == year)
  
  locations <- with(Current_Year, as.data.frame(cbind(Longitude, Latitude)))
  coordinates(locations) <- ~Longitude+Latitude
  proj4string(locations) <- CRS("+init=epsg:4326")
  
  #make sure shapefile and crime data points have compatible CRS
  proj4string(zip_shp) <- new_CRS
  proj4string(locations) <- new_CRS
  #project data points to polygons
  by_zip <- over(locations, zip_shp)
  
  #count crime per zipcode
  by_zip <- by_zip %>%
    group_by(zip) %>%
    dplyr::summarise(total=n()) %>%
    filter(!is.na(zip)) %>%
    mutate(id = as.character(zip))
  
  #merge crime count per zipcode with shapefile for mapping
  total_map <- left_join(zip_df, by_zip)
  total_map <- total_map %>% mutate(Year = year)
  
  Hotspot_Crime <- rbind(Hotspot_Crime, total_map)
}


# Add demographic information to Model Data

data("df_zip_demographics")
Demographics <- df_zip_demographics %>% mutate(zip = region)
Hotspot_Crime <- inner_join(Hotspot_Crime, Demographics, by="zip") 
Model_Data <- Hotspot_Crime %>%
  select(-c(lat, long, order, piece, group, hole)) %>% distinct


# Nesting data, standardize year variable and create groups of zipcodes based on percentage white 

Model_Data <- transform(Model_Data, zipid=match(zip, unique(zip)))
Model_Data$time = Model_Data$Year-2009
Model_Data$racegr <- ifelse(Model_Data$percent_white >80, 1, 
                            ifelse(Model_Data$percent_white <=80 & Model_Data$percent_white > 60,2,
                                   ifelse(Model_Data$percent_white <=60 & Model_Data$percent_white > 40,3,
                                          ifelse(Model_Data$percent_white <=40 & Model_Data$percent_white > 20,4, 5)))) 
Model_Data$income = scale(Model_Data$per_capita_income)[,1]
```

### Model Data for Violent Crimes
```{r, eval=FALSE, echo=TRUE, message=FALSE, warning=FALSE, comment=NA}
violent = c("ROBBERY", "BATTERY", "BURGLARY", "ASSAULT", "HOMICIDE", "ARSON", "CRIM SEXUAL ASSAULT", "SEX OFFENSE")

#To do analysis on Violent crime
Crime_Violent <- Crime %>%
  filter(Primary.Type %in% violent)

#To do analysis on Non-violent crime
Crime_NViolent <- Crime %>%
  filter(!(Primary.Type %in% violent))

#### Project observations to ZIP codes boundaries
#load shapefile
zip_shp <- readOGR(dsn="Boundaries - ZIP Codes", layer="geo_export_e1262361-5c82-45ee-8427-ef228e06dc4a")
temp <- zip_shp
zip_df <- fortify(temp, region = "zip") #turn shapefile into dataframe

#needs to reassign CRS for shapefile
new_CRS <- CRS("+init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
zip_shp <- sp::spTransform(zip_shp, new_CRS)

#summarize number of crime count per year per zipcode
years_violent <- unique(Crime_Violent$Year)
years_nonviolent <- unique(Crime_NViolent$Year)

Hotspot_Crime_Violent <- data.frame()
Hotspot_Crime_NViolent <- data.frame()

for(i in 1:length(years)){
  year <- years[i]
  Current_Year_Violent <- Crime_Violent %>% filter(Year == year)
  Current_Year_NViolent <- Crime_NViolent %>% filter(Year == year)
  
  locations_violent <- with(Current_Year_Violent, as.data.frame(cbind(Longitude, Latitude)))
  locations_nonviolent <- with(Current_Year_NViolent, as.data.frame(cbind(Longitude, Latitude)))

  coordinates(locations_violent) <- ~Longitude+Latitude
  proj4string(locations_violent) <- CRS("+init=epsg:4326")
  
  coordinates(locations_nonviolent) <- ~Longitude+Latitude
  proj4string(locations_nonviolent) <- CRS("+init=epsg:4326")
  
  #make sure shapefile and crime data points have compatible CRS
  proj4string(zip_shp) <- new_CRS
  proj4string(locations_violent) <- new_CRS
  proj4string(locations_nonviolent) <- new_CRS

  #project data points to polygons
  by_zip <- over(locations_violent, zip_shp)
  by_zip <- over(locations_nonviolent, zip_shp)
  
  #count crime per zipcode
  by_zip <- by_zip %>%
    group_by(zip) %>%
    dplyr::summarise(total=n()) %>%
    filter(!is.na(zip)) %>%
    mutate(id = as.character(zip))
  
  #merge crime count per zipcode with shapefile for mapping
  total_map <- left_join(zip_df, by_zip)
  total_map_violent <- total_map %>% mutate(Year = year_violent)
  total_map_nonviolent <- total_map %>% mutate(Year = year_nonviolent)

  Hotspot_Crime_Violent <- rbind(Hotspot_Crime_Violent, total_map_violent)
  Hotspot_Crime_NViolent <- rbind(Hotspot_Crime_NViolent, total_map_nonviolent)

}

# Add demographic information to Model Data

data("df_zip_demographics")
Demographics <- df_zip_demographics %>% mutate(zip = region)
Hotspot_Crime_Violent <- inner_join(Hotspot_Crime_Violent, Demographics, by="zip") 
Hotspot_Crime_NViolent <- inner_join(Hotspot_Crime_NViolent, Demographics, by="zip") 

Model_Data_Violent <- Hotspot_Crime_Violent %>%
  select(-c(lat, long, order, piece, group, hole)) %>% distinct

Model_Data_Nviolent <- Hotspot_Crime_NViolent %>%
  select(-c(lat, long, order, piece, group, hole)) %>% distinct


# Nesting data, standardize year variable and create groups of zipcodes based on percentage white 

Model_Data_Violent <- transform(Model_Data_Violent, zipid=match(zip, unique(zip)))
Model_Data_Violent$time = Model_Data_Violent$Year-2009
Model_Data_Violent$racegr <- ifelse(Model_Data_Violent$percent_white >80, 1, 
                            ifelse(Model_Data_Violent$percent_white <=80 & Model_Data_Violent$percent_white > 60,2,
                                   ifelse(Model_Data_Violent$percent_white <=60 & Model_Data_Violent$percent_white > 40,3,
                                          ifelse(Model_Data_Violent$percent_white <=40 & Model_Data_Violent$percent_white > 20,4, 5)))) 
Model_Data_Violent$income = scale(Model_Data_Violent$per_capita_income)[,1]

## Non-violent crime
Model_Data_Nviolent <- transform(Model_Data_Nviolent, zipid=match(zip, unique(zip)))
Model_Data_Nviolent$time = Model_Data_Nviolent$Year-2009
Model_Data_Nviolent$racegr <- ifelse(Model_Data_Nviolent$percent_white >80, 1, 
                            ifelse(Model_Data_Nviolent$percent_white <=80 & Model_Data_Nviolent$percent_white > 60,2,
                                   ifelse(Model_Data_Nviolent$percent_white <=60 & Model_Data_Nviolent$percent_white > 40,3,
                                          ifelse(Model_Data_Nviolent$percent_white <=40 & Model_Data_Nviolent$percent_white > 20,4, 5)))) 
Model_Data_Nviolent$income = scale(Model_Data_Nviolent$per_capita_income)[,1]
```


---------------------------------------------------------------------------------

#### RJags Code
##### Crime Model 1
```{r, eval=FALSE, echo=TRUE, message=FALSE, warning=FALSE, comment=NA}
#Data
#we only use train data for all crime type model to test its prediction later
data = list(y=train_data$total, n=train_data$total_population, time=train_data$time, zipid=train_data$zipid, ns=length(train_data$total), nzip=length(unique(train_data$id)))

data.V = list(y=Model_Data_Violent$total, n=Model_Data_Violent$total_population, time=Model_Data_Violent$time, zipid=Model_Data_Violent$zipid, ns=length(Model_Data_Violent$total), nzip=length(unique(Model_Data_Violent$id)))

data.NV = list(y=Model_Data_Nviolent$total, n=Model_Data_Nviolent$total_population, time=Model_Data_Nviolent$time, zipid=Model_Data_Nviolent$zipid, ns=length(Model_Data_Nviolent$total), nzip=length(unique(Model_Data_Nviolent$id)))
```

```{r, eval=FALSE, echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
#Specify the model
crime_model_1 <- "model{
    #Data
    for(i in 1:ns) {
      y[i] ~ dbin(p[i], n[i])
      logit(p[i]) = beta[zipid[i]] + delta[zipid[i]]*time[i]
    }
    
    #Priors
    for(j in 1:nzip){
      delta[j] ~ dnorm(delta0, tau_1)
      beta[j] ~ dnorm(beta0, tau_0)
    }
    beta0 ~ dnorm(0, 1/1000^2)
    delta0 ~ dnorm(0, 1/1000^2)

    #Hyperpriors
    tau_0 ~ dgamma(0.5, 0.0005)
    tau_1 ~ dgamma(0.5, 0.0005)
    
}"

#set up an algorithm to simulate the posterior
#set the random number seed
init.rng1<-list(".RNG.seed" = 1998, ".RNG.name" = "base::Mersenne-Twister")
crime_jags_1 <- jags.model(textConnection(crime_model_1), data=data,
                    inits=init.rng1)
crimeV_jags_1 <- jags.model(textConnection(crime_model_1), data=data.V,
                    inits=init.rng1)
crimeNV_jags_1 <- jags.model(textConnection(crime_model_1), data=data.NV,
                    inits=init.rng1)

#simulate a sample from the posterior 
crime_sim_1 <- coda.samples(crime_jags_1, variable.names=c("delta", "beta", "beta0", "delta0", "tau_0", "tau_1"), n.iter=30000)
crimeV_sim_1 <- coda.samples(crimeV_jags_1, variable.names=c("delta", "beta", "beta0", "delta0", "tau_0", "tau_1"), n.iter=30000)
crimeNV_sim_1 <- coda.samples(crimeNV_jags_1, variable.names=c("delta", "beta", "beta0", "delta0", "tau_0", "tau_1"), n.iter=30000)


#store the samples in a data frame:    
crime_data_1 <- data.frame( crime_sim_1[[1]])
crimeV_data_1 <- data.frame(crimeV_sim_1[[1]])
crimeNV_data_1 <- data.frame(crimeNV_sim_1[[1]])
```

#### Crime Model 2
```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
temp <- train_data %>% filter(!duplicated(zipid))
data.2 = list(y=train_data$total, 
            n=train_data$total_population, 
            zipid=train_data$zipid, 
            racegr=train_data$racegr, 
            income=train_data$income, 
            ns=nrow(train_data), 
            time=train_data$time, 
            nzip=length(unique(train_data$zip)),
            raceid = temp$racegr,
            incomezip = temp$income)

temp.V <- Model_Data_Violent %>% filter(!duplicated(zipid))
temp.NV <- Model_Data_Nviolent %>% filter(!duplicated(zipid))

data.V.2 = list(y=Model_Data_Violent$total, 
            n=Model_Data_Violent$total_population, 
            zipid=Model_Data_Violent$zipid, 
            racegr=Model_Data_Violent$racegr, 
            income=Model_Data_Violent$income, 
            ns=nrow(Model_Data_Violent), 
            time=Model_Data_Violent$time, 
            nzip=length(unique(Model_Data_Violent$zip)),
            raceid = temp.V$racegr,
            incomezip = temp.V$income)

data.NV.2 = list(y=Model_Data_Nviolent$total, 
            n=Model_Data_Nviolent$total_population, 
            zipid=Model_Data_Nviolent$zipid, 
            racegr=Model_Data_Nviolent$racegr, 
            income=Model_Data_Nviolent$income, 
            ns=nrow(Model_Data_Nviolent), 
            time=Model_Data_Nviolent$time, 
            nzip=length(unique(Model_Data_Nviolent$zip)),
            raceid = temp.NV$racegr,
            incomezip = temp.NV$income)
```

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
#Specify the model
crime_model_2 <- "model{
    #Data
    for(i in 1:ns) {
      y[i] ~ dbin(p[i], n[i])
      logit(p[i]) = beta[zipid[i]] + delta[zipid[i]]*time[i] 
    }
    
    #Priors
    for(i in 1:nzip){
      beta[i] ~ dnorm(beta0 + sigma[raceid[i]]*incomezip[i], tau_0)
      delta[i] ~ dnorm(delta0, tau_1)
    }
    beta0 ~ dnorm(0, 1/1000^2)
    delta0 ~ dnorm(0, 1/1000^2)
    sigma0 ~ dnorm(0, 1/1000^2)
    for(j in 1:5){
      sigma[j] ~ dnorm(sigma0, tau_2)
    }

    #Hyperpriors
    tau_0 ~ dgamma(0.5, 0.0005)
    tau_1 ~ dgamma(0.5, 0.0005)
    tau_2 ~ dgamma(0.5, 0.0005)
    
}"

#set up an algorithm to simulate the posterior by 
#combining the model (nba_model) and data (y)
#set the random number seed
crime_jags_2 <- jags.model(textConnection(crime_model_2), data=data.2,
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))
crimeV_jags_2 <- jags.model(textConnection(crime_model_2), data=data.V.2,
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))
crimeNV_jags_2 <- jags.model(textConnection(crime_model_2), data=data.NV.2,
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))

#Simulate a sample from the posterior 
crime_sim_2 <- coda.samples(crime_jags_2, variable.names=c("beta", "beta0", "delta", "delta0","sigma","sigma0", "tau_0","tau_1","tau_2"), n.iter=30000)
crimeV_sim_2 <- coda.samples(crimeV_jags_2, variable.names=c("beta", "beta0", "delta", "delta0","sigma","sigma0", "tau_0","tau_1","tau_2"), n.iter=30000)
crimeNV_sim_2 <- coda.samples(crimeNV_jags_2, variable.names=c("beta", "beta0", "delta", "delta0","sigma","sigma0", "tau_0","tau_1","tau_2"), n.iter=30000)

#Store the samples in a data frame:    
crime_data_2 <- data.frame(crime_sim_2[[1]])
crimeV_data_2 <- data.frame(crimeV_sim_2[[1]])
crimeNV_data_2 <- data.frame(crimeNV_sim_2[[1]])

#save data
# save(crime_sim_2, file="model_2_MCMC_sim_train.Rda")
# save(crime_data_2, file="model_2_MCMC_samples_train.Rda")
# save(crimeV_sim_2, file="model_2_MCMC_sim_violent.Rda")
# save(crimeV_data_2, file="model_2_MCMC_samples_violent.Rda")
# save(crimeNV_sim_2, file="model_2_MCMC_sim_non-violent.Rda")
# save(crimeNV_data_2, file="model_2_MCMC_samples_non-violent.Rda")
```

#### Crime Model 3

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
#making data for model 3
temp <- train_data %>% filter(!duplicated(zipid))

#orthogonalize income, and interaction of income and percent white since they are correlated
decomp <- qr(cbind(temp$income, temp$percent_white, temp$income*temp$percent_white))
Q <- qr.Q(decomp)
R <- qr.R(decomp)
data.3 = list(ns=nrow(train_data), 
            y=train_data$total, 
            n=train_data$total_population,
            time=train_data$time, 
            nzip=length(unique(train_data$zipid)), 
            zipid=train_data$zipid, 
            incomezip=Q[,1], 
            whitezip=Q[,2],
            interactionzip = Q[,3])

temp <- Model_Data_Violent %>% filter(!duplicated(zipid))
#orthogonalize income, and interaction of income and percent white since they are correlated
decomp <- qr(cbind(temp$income, temp$percent_white, temp$income*temp$percent_white))
Q <- qr.Q(decomp)
R <- qr.R(decomp)
data.V.3 = list(ns=nrow(Model_Data_Violent), 
            y=Model_Data_Violent$total, 
            n=Model_Data_Violent$total_population,
            time=Model_Data_Violent$time, 
            nzip=length(unique(Model_Data_Violent$zipid)), 
            zipid=Model_Data_Violent$zipid, 
            incomezip=Q[,1], 
            whitezip=Q[,2],
            interactionzip = Q[,3])

temp <- Model_Data_Nviolent %>% filter(!duplicated(zipid))
#orthogonalize income, and interaction of income and percent white since they are correlated
decomp <- qr(cbind(temp$income, temp$percent_white, temp$income*temp$percent_white))
Q <- qr.Q(decomp)
R <- qr.R(decomp)
data.NV.3 = list(ns=nrow(Model_Data_Nviolent), 
            y=Model_Data_Nviolent$total, 
            n=Model_Data_Nviolent$total_population,
            time=Model_Data_Nviolent$time, 
            nzip=length(unique(Model_Data_Nviolent$zipid)), 
            zipid=Model_Data_Nviolent$zipid, 
            incomezip=Q[,1], 
            whitezip=Q[,2],
            interactionzip = Q[,3])
```


```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
#Specify the model
crime_model_3 <- "model{
    #Data
    for(i in 1:ns) {
      y[i] ~ dbin(p[i], n[i])
      logit(p[i]) = beta[zipid[i]] + delta[zipid[i]]*time[i] 
    }
    
    #Priors
    beta0 ~ dnorm(0, 1/1000^2)
    delta0 ~ dnorm(0, 1/1000^2)
    for(i in 1:nzip){
      beta[i] ~ dnorm(beta0 + sigma[1]*incomezip[i] + sigma[2]*whitezip[i] + sigma[3]*interactionzip[i], tau_0)
      delta[i] ~ dnorm(delta0, tau_1)
    }
    for(i in 1:3){
      sigma[i] ~ dnorm(0, 1/1000^2)
    }
    tau_0 ~ dgamma(0.5, 0.0005)
    tau_1 ~ dgamma(0.5, 0.0005)
    
}"

#set up an algorithm to simulate the posterior by 
#combining the model (nba_model) and data (y)
#set the random number seed
crime_jags_3 <- jags.model(textConnection(crime_model_3), data=data.3,
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))
crimeV_jags_3 <- jags.model(textConnection(crime_model_3), data=data.V.3,
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))
crimeNV_jags_3 <- jags.model(textConnection(crime_model_3), data=data.NV.3,
                    inits=list(.RNG.name="base::Wichmann-Hill", .RNG.seed=1989))


#simulate a sample from the posterior 
#note that we specify both mu and tau variables
crime_sim_3 <- coda.samples(crime_jags_3, variable.names=c("beta", "beta0","delta","delta0", "sigma", "tau_0", "tau_1"), n.iter=30000)
crimeV_sim_3 <- coda.samples(crimeV_jags_3, variable.names=c("beta", "beta0","delta","delta0", "sigma", "tau_0", "tau_1"), n.iter=30000)
crimeNV_sim_3 <- coda.samples(crimeNV_jags_3, variable.names=c("beta", "beta0","delta","delta0", "sigma", "tau_0", "tau_1"), n.iter=30000)

#store the samples in a data frame:    
crime_data_3 <- data.frame(crime_sim_3[[1]])
crimeV_data_3 <- data.frame(crimeV_sim_3[[1]])
crimeNV_data_3 <- data.frame(crimeNV_sim_3[[1]])

#save data
# save(crime_sim_3, file="model_3_MCMC_sim_train.Rda")
# save(crime_data_3, file="model_3_MCMC_samples_train.Rda")
# save(crimeV_sim_3, file="model_3_MCMC_sim_violent.Rda")
# save(crimeV_data_3, file="model_3_MCMC_samples_violent.Rda")
# save(crimeNV_sim_3, file="model_3_MCMC_sim_non-violent.Rda")
# save(crimeNV_data_3, file="model_3_MCMC_samples_non-violent.Rda")
```


--------------------------------------------------------

#### Visualization Code

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
# Load the necessary datasets
Crime <- read.csv('Crime_sample_2010_to_2017.csv')
Model_Data <- read.csv("Crime_models_data.csv")
Model_Data_Violent <- read.csv("Crime_models_violent_data.csv")
Model_Data_Nviolent <- read.csv("Crime_models_nonviolent_data.csv")

train_data <- Model_Data %>% filter(Year < 2016)
test_data <- Model_Data %>% filter(Year==2016)

load("model_1_MCMC_samples_train.Rda")
load("model_2_MCMC_samples_train.Rda")
load("model_3_MCMC_samples_train.Rda")
load("model_1_MCMC_samples_non-violent.Rda")
load("model_1_MCMC_samples_violent.Rda")
load("model_2_MCMC_samples_non-violent.Rda")
load("model_2_MCMC_samples_violent.Rda")
load("model_3_MCMC_samples_non-violent.Rda")
load("model_3_MCMC_samples_violent.Rda")
```

##### Figure 1:

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
# Map cleanup: remove grey background grids in maps visualizations
cleanup <- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = 'white', colour = 'white'),
        axis.line = element_line(colour = "white"),
        axis.ticks=element_blank(), axis.text.x=element_blank(),
        axis.text.y=element_blank())
```

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
#load the shape file to make maps
zip <- readOGR(dsn="Boundaries - ZIP Codes", layer="geo_export_e1262361-5c82-45ee-8427-ef228e06dc4a")
```

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
# Make density map of crime incidents in year 2010, 2013, 2016 to see if there is time trend
Crime_2010 <- Crime %>% filter(Year == 2010)
gg2010 <- ggplot()
gg2010 <- gg2010 + geom_polygon(data=zip, aes(x=long, y=lat, group=group), colour="black", fill="grey90", size=0.5) 
gg2010 <- gg2010 + stat_density2d(data=Crime_2010, show.legend=F, aes(x=Longitude, y=Latitude, fill=..level.., alpha=..level..), geom="polygon", size=2, bins=10)
gg2010 <- gg2010 + scale_fill_gradient(low="deepskyblue2", high="firebrick1", name="Distribution")
gg2010 <- gg2010 +  coord_map("polyconic")
gg2010 <- gg2010 + labs(x=NULL, y=NULL,
                  subtitle=NULL,
                  caption="2010")
gg2010 <- gg2010 + cleanup + theme(plot.margin = unit(c(0,0,0,0), "lines"))

Crime_2013 <- Crime %>% filter(Year == 2013)
gg2013 <- ggplot()
gg2013 <- gg2013 + geom_polygon(data=zip, aes(x=long, y=lat, group=group), colour="black", fill="grey90", size=0.5) 
gg2013 <- gg2013 + stat_density2d(data=Crime_2013, show.legend=F, aes(x=Longitude, y=Latitude, fill=..level.., alpha=..level..), geom="polygon", size=2, bins=10)
gg2013 <- gg2013 + scale_fill_gradient(low="deepskyblue2", high="firebrick1", name="Distribution")
gg2013 <- gg2013 +  coord_map("polyconic")
gg2013 <- gg2013 + labs(x=NULL, y=NULL,
                  subtitle=NULL,
                  caption="2013")
gg2013 <- gg2013 + cleanup + theme(plot.margin = unit(c(0,0,0,0), "lines"))


Crime_2016 <- Crime %>% filter(Year == 2016)
gg2016 <- ggplot()
gg2016 <- gg2016 + geom_polygon(data=zip, aes(x=long, y=lat, group=group), colour="black", fill="grey90", size=0.5) 
gg2016 <- gg2016 + stat_density2d(data=Crime_2016, show.legend=F, aes(x=Longitude, y=Latitude, fill=..level.., alpha=..level..), geom="polygon", size=2, bins=10)
gg2016 <- gg2016 + scale_fill_gradient(low="deepskyblue2", high="firebrick1", name="Distribution")
gg2016 <- gg2016 +  coord_map("polyconic")
gg2016 <- gg2016 + labs(x=NULL, y=NULL,
                  subtitle=NULL,
                  caption="2016")
gg2016 <- gg2016 + cleanup + theme(plot.margin = unit(c(0,0,0,0), "lines"))

grid.arrange(gg2010, gg2013, gg2016, ncol=3, heights=15, top=textGrob("Figure 1: Concentration of Crime in Chicago", gp=gpar(fontsize=20, fontface="bold")))
```

##### Figure 2:

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
# Visualizations of demographics data in 2010
data(df_pop_zip)
data(df_zip_demographics)

zip_percent_white <- df_zip_demographics[c("region", "percent_white")]
colnames(zip_percent_white)[2] <- "value"

zip_percent_black <- df_zip_demographics[c("region", "percent_black")]
colnames(zip_percent_black)[2] <- "value"

zip_percent_asian <- df_zip_demographics[c("region", "percent_asian")]
colnames(zip_percent_asian)[2] <- "value"

zip_percent_hispanic <- df_zip_demographics[c("region", "percent_hispanic")]
colnames(zip_percent_hispanic)[2] <- "value"

zip_per_capita_income <- df_zip_demographics[c("region", "per_capita_income")]
colnames(zip_per_capita_income)[2] <- "value"

zip_median_rent <- df_zip_demographics[c("region", "median_rent")]
colnames(zip_median_rent)[2] <- "value"

zip_median_age <- df_zip_demographics[c("region", "median_age")]
colnames(zip_median_age)[2] <- "value"

data(zip.regions)
chi_nap_elg <- subset(zip.regions, zip.regions$cbsa.title=="Chicago-Naperville-Elgin, IL-IN-WI")
cook_county <- subset(chi_nap_elg, chi_nap_elg$county.name == "cook")
cook_fips <- cook_county$county.fips.numeric
```

##### Figure 3:

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
pop_map <- zip_choropleth(df_pop_zip, 
               county_zoom = cook_fips, 
               title="Total Population") + coord_map()

white_pop_map <- zip_choropleth(zip_percent_white, 
               county_zoom = cook_fips, 
               title="White Population") + coord_map()

black_pop_map <- zip_choropleth(zip_percent_black, 
               county_zoom = cook_fips, 
               title="Black Population") + coord_map()

asian_pop_map <- zip_choropleth(zip_percent_asian, 
               county_zoom = cook_fips, 
               title="Asian Population") + coord_map()

hisp_pop_map <- zip_choropleth(zip_percent_hispanic, 
               county_zoom = cook_fips, 
               title="Hispanic Population") + coord_map()

income_map <- zip_choropleth(zip_per_capita_income, 
               county_zoom = cook_fips, 
               title="Per Capita Income") + coord_map()

rent_map <- zip_choropleth(zip_median_rent, 
               county_zoom = cook_fips, 
               title="Median Rent") + coord_map()

age_map <- zip_choropleth(zip_median_age, 
               county_zoom = cook_fips, 
               title="Median Age") + coord_map()

grid.arrange(pop_map, white_pop_map, black_pop_map, asian_pop_map, hisp_pop_map, income_map, rent_map, age_map, ncol=3, top=textGrob("Figure 2: Demographic Maps of Chicago by Zipcode", gp=gpar(fontsize=20, fontface="bold")))
```

##### Figure 4:

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
Crime_count <- Model_Data %>%
  select(Year, zip, total) %>%
  spread(key=Year, value=total)
rownames(Crime_count) <- Crime_count$zip 
Crime_count <- Crime_count %>% select(-zip)
Crime_count[is.na(Crime_count)] <- 0

Population <- Model_Data %>%
  select(total_population, zip, Year) %>%
  spread(key=Year, value=total_population) %>%
  select('2010', zip)
rownames(Population) <- Population$zip
Population <- Population %>% select(-zip)
Population[is.na(Population)] <- 0
Population.vector <- Population$`2010`

Crime_count_log_calc <- log(Crime_count/Population.vector)
Crime_count_log <- Crime_count_log_calc %>%
  rownames_to_column() %>%
  gather(key=year, value=crime_count_log, -rowname) %>%
  mutate(zip=rowname) %>%
  select(zip, year, crime_count_log) %>%
  mutate(year=as.numeric(year))

ggplot(Crime_count_log, aes(x=year, y=crime_count_log, colour=zip)) + geom_point() + geom_line() + labs(title="Figure 3: Crime Rate Over Time", y="Log of Crime Rate", x="Year", color="Zipcodes")
```

##### Figure 5:

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
#Create a data frame containing posterior means for each zipcode
n = length(unique(train_data$zip))
crime_model_1_mean <- matrix(nrow=n, ncol=1) #find posterior means of delta_i
for (i in 1:n) {
      crime_model_1_mean[i, ] <- mean(crime_data_1[[i+59]])
}
zip_df <- fortify(zip, region = "zip")
crime_model_1_delta <- left_join(zip_df, data.frame(id=as.character(unique(train_data$zip)), delta=crime_model_1_mean), by='id')
```

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
#Make a map
model_1_map <- ggplot() 
model_1_map <- model_1_map +  geom_polygon(data = crime_model_1_delta, aes(x=long, y=lat, group=group, fill=delta), color = "black", size=0.2) 
model_1_map <- model_1_map + coord_map() 
model_1_map <- model_1_map + labs(x="", y="", title=paste("Figure 4: Crime Differential Growth by Zipcode"), caption="Model 1", fill="Trend over Time")
model_1_map <- model_1_map + cleanup + scale_fill_gradient(low = "blue", high = "orange")
print(model_1_map)
```

##### Figure 6:

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
posterior_means <- crimeV_data_2 %>% colMeans()
crimeV_model_2_sigma <- Model_Data_Violent
crimeV_model_2_sigma$sigma <- recode(crimeV_model_2_sigma$racegr, `1`=posterior_means[start_index],
                                   `2`=posterior_means[start_index+1],
                                   `3`=posterior_means[start_index+2],
                                   `4`=posterior_means[start_index+3],
                                   `5`=posterior_means[start_index+4])
crimeV_model_2_sigma <- crimeV_model_2_sigma %>%
  mutate(id = as.character(zip)) %>%
  right_join(zip_df, by="id")

posterior_means <- crimeNV_data_2 %>% colMeans()
crimeNV_model_2_sigma <- Model_Data_Nviolent
crimeNV_model_2_sigma$sigma <- recode(crimeNV_model_2_sigma$racegr, `1`=posterior_means[start_index],
                                   `2`=posterior_means[start_index+1],
                                   `3`=posterior_means[start_index+2],
                                   `4`=posterior_means[start_index+3],
                                   `5`=posterior_means[start_index+4])
crimeNV_model_2_sigma <- crimeNV_model_2_sigma %>%
  mutate(id = as.character(zip)) %>%
  right_join(zip_df, by="id")
```

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
model_2_map_v <- ggplot() 
model_2_map_v <- model_2_map_v +  geom_polygon(data = crimeV_model_2_sigma, aes(x=long, y=lat, group=group, fill=sigma), color = "black", size=0.2) 
model_2_map_v <- model_2_map_v + coord_map() 
model_2_map_v <- model_2_map_v + labs(x="", y="", title=paste("Violent Crime"), fill="Trend over Income", caption="Model 2")
model_2_map_v <- model_2_map_v + cleanup + scale_fill_gradient(low = "blue", high = "orange", limits=c(-1.2,0.8))
```

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}
model_2_map_nv <- ggplot() 
model_2_map_nv <- model_2_map_nv +  geom_polygon(data = crimeNV_model_2_sigma, aes(x=long, y=lat, group=group, fill=sigma), color = "black", size=0.2) 
model_2_map_nv <- model_2_map_nv + coord_map() 
model_2_map_nv <- model_2_map_nv + labs(x="", y="", title=paste("Non-violent Crime"), fill="Trend over Income", caption="Model 2")
model_2_map_nv <- model_2_map_nv + cleanup + scale_fill_gradient(low = "blue", high = "orange", limits=c(-1.2,0.8))

grid.arrange(model_2_map_v, model_2_map_nv, ncol=2, top=textGrob("Figure 8: Crime Differential Growth Based on Income, Demographics, and Type of Crime", gp=gpar(fontsize=20, fontface="bold")))
```


##### Figure 7:

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}

crime_data_3 <- crime_data_3[20000:nrow(crime_data_3), ]
crime_data_3_sum <- as.data.frame(colMeans(crime_data_3))

model_3_predictor <- function(param, income, percent_nonwhite, year, population){
   c <- (param[1,1] + param[2,1] * year + param[3,1] * income + param[4,1] * percent_nonwhite + param[5,1] * percent_nonwhite * income)
   p <- exp(c)/(1 + exp(c))
   return(p * population)
}

predicted_crime_count <- model_3_predictor(crime_data_3_sum, test_data$income, test_data$percent_white, test_data$time, test_data$total_population)

actual_crime_count <- test_data$total 
crime_count_diff <- predicted_crime_count - actual_crime_count

crime_model_3_count_diff <- left_join(zip_df, data.frame(id=as.character(unique(test_data$zip)), crime_difference=crime_count_diff), by='id')
head(crime_model_3_count_diff)
```

```{r, eval=FALSE, echo=TRUE, cache=TRUE, message=FALSE, warning=FALSE}

model_3_map <- ggplot() 
model_3_map <- model_3_map +  geom_polygon(data = crime_model_3_count_diff, aes(x=long, y=lat, group=group, fill=crime_difference), color = "black", size=0.2) 
model_3_map <- model_3_map + coord_map() 
model_3_map <- model_3_map + labs(x="", y="", title=paste("Figure 9: Difference in Crime Count by Zipcode"), caption="Model 3", fill="Count Difference")
model_3_map <- model_3_map + cleanup + scale_fill_gradient(low = "blue", high = "orange") + theme(plot.title = element_text(size=18))
print(model_3_map)
```
